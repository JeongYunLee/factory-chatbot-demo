import uuid, os, io, sys, time, json
import asyncio
import threading
from contextlib import asynccontextmanager
from dotenv import load_dotenv
from typing import TypedDict, Annotated
import pandas as pd
import numpy as np
from functools import wraps

from openai import OpenAI
from langchain_openai import ChatOpenAI
# import chromadb
# from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings

from langchain_community.tools.tavily_search import TavilySearchResults

from langgraph.graph import END, StateGraph
from langgraph.checkpoint.memory import MemorySaver
from langgraph.errors import GraphRecursionError

from langchain_core.output_parsers import JsonOutputParser
from langchain_core.output_parsers.openai_tools import JsonOutputToolsParser
from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_core.prompts import PromptTemplate
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnableConfig  
from langchain_core.output_parsers import StrOutputParser

from langchain_community.chat_message_histories import ChatMessageHistory, StreamlitChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from langgraph.graph.message import add_messages
from operator import itemgetter

from langchain.agents import tool
from langchain.agents import create_tool_calling_agent
from langchain.agents import AgentExecutor

# from langchain_teddynote import logging
from langsmith import traceable
import threading

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv(override=True)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise ValueError("OPENAI_API_KEY not found in environment variables")

# ëª¨ë¸
model = ChatOpenAI(
    openai_api_key=OPENAI_API_KEY,
    model="gpt-5.1-2025-11-13",
    temperature=0
)

df = pd.read_csv('data/cleaned_ì „êµ­ê³µì¥ë“±ë¡í˜„í™©_preprocessed_seoul.csv')

###################################################################################################

class GraphState(TypedDict):
    question: str  # ì§ˆë¬¸
    q_type: str  # ì§ˆë¬¸ì˜ ìœ í˜•
    answer: str | list[str]  # llmì´ ìƒì„±í•œ ë‹µë³€
    session_id: str  # ì„¸ì…˜ ID
    context: str | None  # ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸
    relevance: str | None  # ê²€ìƒ‰ ì í•©ë„

# ğŸ”§ ê°œì„  1: ìŠ¤ë ˆë“œ ì•ˆì „í•œ ì €ì¥ì†Œ
import threading
from collections import defaultdict

class ThreadSafeStore:
    def __init__(self):
        self._store = {}
        self._lock = threading.RLock()  # ì¬ì§„ì… ê°€ëŠ¥í•œ ë½
    
    def get_session_history(self, session_id: str):
        with self._lock:
            if session_id not in self._store:
                self._store[session_id] = ChatMessageHistory()
                print(f"ğŸ†• ìƒˆë¡œìš´ ì„¸ì…˜ íˆìŠ¤í† ë¦¬ ìƒì„±: {session_id[:8]}...")
            return self._store[session_id]
    
    def clear_session(self, session_id: str = None):
        with self._lock:
            if session_id:
                if session_id in self._store:
                    message_count = len(self._store[session_id].messages)
                    del self._store[session_id]
                    return message_count
                return 0
            else:
                total_sessions = len(self._store)
                total_messages = sum(len(history.messages) for history in self._store.values())
                self._store.clear()
                return total_sessions, total_messages
    
    def get_stats(self):
        with self._lock:
            return {
                'total_sessions': len(self._store),
                'total_messages': sum(len(history.messages) for history in self._store.values())
            }

# ì „ì—­ ìŠ¤ë ˆë“œ ì•ˆì „ ì €ì¥ì†Œ
thread_safe_store = ThreadSafeStore()

# ì„¸ì…˜ IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
def get_session_history(session_ids):
    return thread_safe_store.get_session_history(session_ids)

# ìƒˆë¡œìš´ ì„¸ì…˜ ID ìƒì„± í•¨ìˆ˜
def generate_session_id():
    return str(uuid.uuid4())

#######################################################################
############################ nodes: Router ############################
#######################################################################

class Router(BaseModel):
    type: str = Field(description="type of the query that model choose. Choose from ['general', 'domain_specific']")

router_output_parser = JsonOutputParser(pydantic_object=Router)
router_format_instructions = router_output_parser.get_format_instructions()

router_prompt = PromptTemplate(
    template="""
            You are an expert who classifies the type of question. There are two query types: ['general', 'domain_specific']

            [general]
            Questions unrelated to data query, such as translating English to Korean, asking for general knowledge (e.g., "What is the capital of South Korea?"), or queries that can be answered through a web search.

            [domain_specific]
            Questions related to 'factory' domain and data query, such as 'count the unique values of factories in Seoul', or count 'the number of rows in a table'.

            <Output format>: Always respond with either "general" or "domain_specific" and nothing else. {format_instructions}
            <chat_history>: {chat_history}
            
            <Question>: {query} 
            """,
    input_variables=["query", "chat_history"],
    partial_variables={"format_instructions": router_format_instructions},
)

def router(state: GraphState) -> GraphState:
    chain = router_prompt | model | router_output_parser
    
    router_with_history  = RunnableWithMessageHistory(
        chain,
        get_session_history,
        input_messages_key="query",
        history_messages_key="chat_history",
    )
    
    router_result = router_with_history.invoke(
        {"query": state["question"]}, 
        {'configurable': {'session_id': state["session_id"]}}
    )
    state["q_type"] = router_result['type']
    return state

def router_conditional_edge(state: GraphState) -> GraphState:
    q_type = state["q_type"].strip()
    return q_type

##################################################################################
###################### nodes: Generate Python Pandas Code ########################
##################################################################################

class CodeGenerator(BaseModel):
    code: str = Field(description="Python Pandas Code")

code_generator_output_parser = JsonOutputParser(pydantic_object=CodeGenerator)
code_generator_format_instructions = code_generator_output_parser.get_format_instructions()

code_generator_prompt = PromptTemplate(
    template="""
            You are an expert who can generate Python Pandas Code to answer the query.

            Write the code with the following dataset metadata. Do not use any other columns except the ones provided in the metadata. The columns are written in Korean.

            <Dataset Metadata>: 
            # Basic Information
            1. 'ê³µì¥ê´€ë¦¬ë²ˆí˜¸' (Factory Management Number): Unique factory identification number. [Important] A single factory management number can appear across multiple rows. When counting the number of factories, always use unique/distinct values of this field.

            # Company & Factory Information
            2. 'íšŒì‚¬ëª…' (Company Name): Name of the company operating the factory. It's not unique. 
            3. 'ê³µì¥êµ¬ë¶„' (Factory Classification): Type/classification of the factory
            4. 'ë‹¨ì§€ëª…' (Complex Name): Name of the industrial complex (if applicable)
            5. 'ì„¤ë¦½êµ¬ë¶„' (Establishment Type): Classification of how the factory was established
            6. 'ì…ì£¼í˜•íƒœ' (Occupancy Type): Type of occupancy arrangement
            7. 'ë“±ë¡êµ¬ë¶„' (Registration Type): Classification of factory registration
            8. 'ì „í™”ë²ˆí˜¸' (Phone Number): Contact phone number


            # Employee Statistics
            9. 'ë‚¨ìì¢…ì—…ì›' (Male Employees): Number of male employees
            10. 'ì—¬ìì¢…ì—…ì›' (Female Employees): Number of female employees
            11. 'ì™¸êµ­ì¸ë‚¨ìì¢…ì—…ì›' (Foreign Male Employees): Number of foreign male employees
            12. 'ì™¸êµ­ì¸ì—¬ìì¢…ì—…ì›' (Foreign Female Employees): Number of foreign female employees
            13. 'ì¢…ì—…ì›í•©ê³„' (Total Employees): Total number of employees

            # Production Information
            14. 'ìƒì‚°í’ˆ' (Products): Products manufactured at the factory
            15. 'ì›ìì¬' (Raw Materials): Raw materials used in production
            16. 'ê³µì¥ê·œëª¨' (Factory Scale): Size classification of the factory
            
            # Facility Specifications
            17. 'ìš©ì§€ë©´ì ' (Land Area): Total land area in square meters
            18. 'ì œì¡°ì‹œì„¤ë©´ì ' (Manufacturing Facility Area): Area dedicated to manufacturing facilities
            19. 'ë¶€ëŒ€ì‹œì„¤ë©´ì ' (Auxiliary Facility Area): Area of auxiliary/support facilities
            20. 'ê±´ì¶•ë©´ì ' (Building Area): Total building area
            21. 'ì§€ì‹ì‚°ì—…ì„¼í„°ëª…' (Knowledge Industry Center Name): Name of knowledge industry center (if applicable)

            # Location & Administrative
            22. 'í•„ì§€ìˆ˜' (Number of Parcels): Number of land parcels
            23. 'ê³µì¥ê´€ë¦¬ë²ˆí˜¸' (Factory Management Number): Unique factory identification number

            #Standardized Fields (ì •ì œ_)
            24. 'ì •ì œ_ê´€ë¦¬ê¸°ê´€' (Standardized Management Agency): Standardized name of the management agency 
            25. 'ì •ì œ_ë³´ìœ êµ¬ë¶„' (Standardized Ownership Type): Standardized ownership classification
            26. 'ì •ì œ_ì‹œêµ°êµ¬ëª…' (Standardized District Name): Standardized city/county/district name
            27. 'ì •ì œ_ì‹œë„ëª…' (Standardized Province Name): Standardized province/metropolitan city name
            28. 'ì •ì œ_ì—…ì¢…ëª…' (Standardized Industry Name): Standardized industry name. It's not unique, so you need to calculate with 'ì •ì œ_ëŒ€í‘œì—…ì¢…' and show in 'ì •ì œ_ì—…ì¢…ëª…'
            29. 'ì •ì œ_ëŒ€í‘œì—…ì¢…' (Standardized Primary Industry): Standardized primary industry classification. It's in code, so after use it, you need to show the name using 'ì •ì œ_ëŒ€í‘œì—…ì¢…'
            29. 'ì •ì œ_ìš©ë„ì§€ì—­' (Standardized Zoning District): Standardized zoning/land use district
            30. 'ì •ì œ_ì§€ëª©' (Standardized Land Category): Standardized land category classification

            # Date Fields
            31. 'ì •ì œ_ìµœì´ˆë“±ë¡ì¼' (Standardized Initial Registration Date): Standardized date of initial registration (format: YYYY-MM-DD)
            32. 'ì •ì œ_ìµœì´ˆìŠ¹ì¸ì¼' (Standardized Initial Approval Date): Standardized date of initial approval (format: YYYY-MM-DD)

            Write the code with the most efficient way.
            <Output format>: Always respond with Python Pandas code. Always assign the final result to a variable called `return_var`. Do not use print(). {format_instructions}
            <chat_history>: {chat_history}
            
            <Question>: {query} 
            """,
    input_variables=["query", "chat_history"],
    partial_variables={"format_instructions": code_generator_format_instructions},
)

# @tool
# def code_generator(input):
#     '''
#     ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ CSVì—ì„œ ì¿¼ë¦¬í•  ìˆ˜ ìˆëŠ” Python Pandas ì½”ë“œë¥¼ ì‘ì„±í•˜ëŠ” ë„êµ¬
#     '''
#     chain = code_generator_prompt | model | code_generator_output_parser
    
#     code_generator_with_history  = RunnableWithMessageHistory(
#         chain,
#         get_session_history,
#         input_messages_key="query",
#         history_messages_key="chat_history",
#     )
    
#     code_generator_result = code_generator_with_history.invoke(
#         {"query": input}, 
#         {'configurable': {'session_id': state["session_id"]}}
#     )
#     return code_generator_result['code']

@tool
def code_generator(input, session_id: str | None = None):
    """
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ CSVì—ì„œ ì¿¼ë¦¬í•  ìˆ˜ ìˆëŠ” Python Pandas ì½”ë“œë¥¼ ì‘ì„±í•˜ëŠ” ë„êµ¬
    """
    chain = code_generator_prompt | model | code_generator_output_parser

    resolved_session_id = session_id or generate_session_id()

    code_generator_with_history = RunnableWithMessageHistory(
        chain,
        get_session_history,
        input_messages_key="query",
        history_messages_key="chat_history",
    )

    code_generator_result = code_generator_with_history.invoke(
        {"query": input},
        {'configurable': {'session_id': resolved_session_id}}
    )
    return code_generator_result['code']

@tool
def code_executor(input_code: str, max_retries=3):
    """
    LLMì´ ìƒì„±í•œ Pandas ì½”ë“œë¥¼ ì•ˆì „í•˜ê²Œ ì‹¤í–‰í•˜ê³  return_var ë°˜í™˜.
    dfëŠ” ê¸€ë¡œë²Œ ë³€ìˆ˜ ì‚¬ìš©.
    NA, None, 0 ë“±ì˜ ì—ëŸ¬ ëŒ€ë¹„.
    """
    global df
    local_vars = {'df': df}

    for attempt in range(max_retries):
        try:
            exec(input_code, local_vars)
            if 'return_var' not in local_vars:
                raise ValueError("Generated code did not assign value to 'return_var'.")
            return local_vars['return_var']
        except Exception as e:
            print(f"âš ï¸ ì½”ë“œ ì‹¤í–‰ ì‹¤íŒ¨ (ì‹œë„ {attempt+1}/{max_retries}): {e}")
            # NAë‚˜ boolean ë¹„êµ ì—ëŸ¬ ë“± ì¬ì‹œë„ ê°€ëŠ¥
            if attempt == max_retries - 1:
                raise

############################ tools & Agents ############################

# ğŸ”§ ê°œì„  3: OpenAI API ë ˆì´íŠ¸ ë¦¬ë¯¸íŒ… ë° ì¬ì‹œë„
import openai
from openai import RateLimitError, APITimeoutError

def retry_on_failure(max_retries=3, delay=1):
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            last_exception = None
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    last_exception = e
                    if attempt < max_retries - 1:
                        print(f"âš ï¸ ì‹œë„ {attempt + 1} ì‹¤íŒ¨, {delay}ì´ˆ í›„ ì¬ì‹œë„: {str(e)[:100]}")
                        time.sleep(delay * (attempt + 1))  # ì§€ìˆ˜ ë°±ì˜¤í”„
                    else:
                        print(f"âŒ ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨: {str(e)}")
            raise last_exception
        return wrapper
    return decorator

@retry_on_failure(max_retries=3, delay=2)
def call_openai_with_retry(client, **kwargs):
    try:
        return client.chat.completions.create(**kwargs)
    except RateLimitError as e:
        print(f"âš ï¸ OpenAI ë ˆì´íŠ¸ ë¦¬ë¯¸íŠ¸: {e}")
        time.sleep(5)  # ë ˆì´íŠ¸ ë¦¬ë¯¸íŠ¸ ì‹œ ë” ì˜¤ë˜ ëŒ€ê¸°
        raise
    except APITimeoutError as e:
        print(f"âš ï¸ OpenAI íƒ€ì„ì•„ì›ƒ: {e}")
        raise
    except Exception as e:
        print(f"âš ï¸ OpenAI API ì˜¤ë¥˜: {e}")
        raise
    
tools = [code_generator, code_executor]

agent_prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You are a helpful assistant that answers ONLY in Korean. "
            "You must follow these rules:\n"
            "1. If q_type is 'domain_specific', you MUST use tools to generate code and execute it."
            "2. Use the result of code_executor, which is called 'return_var', to answer."
            "3. ONLY if 'return_var' is empty ([], None, or pd.DataFrame with no rows), respond with 'ì°¸ì¡°í•  ì •ë³´ê°€ ì—†ì–´ì„œ ë‹µë³€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'"
            "4. Otherwise, ALWAYS use 'return_var' as the basis of your answer."
            "Always answer in Korean, never in English."
        ),
        ("placeholder", "{chat_history}"),
        ("human", "{input}"),
        ("human", "{retrieved_data}"),
        ("placeholder", "{agent_scratchpad}"),
    ]
)

def agent(state: GraphState) -> GraphState:
    """
    Agent ì‹¤í–‰ í•¨ìˆ˜
    - domain_specific ì§ˆë¬¸ì€ tools(code_generator + safe_code_executor) ì‚¬ìš©
    - code ì‹¤í–‰ ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ êµ¬ì¡° ì ìš©
    """
    session_id = state["session_id"]
    # íˆìŠ¤í† ë¦¬ì— dict ê·¸ëŒ€ë¡œ ë„£ì§€ ë§ê³  ë¬¸ìì—´ë¡œ ë³€í™˜
    chat_history = get_session_history(session_id)
    chat_history.add_user_message(f"question: {state['question']}, q_type: {state['q_type']}")

    try:
        # Agent ìƒì„±
        agent_obj = create_tool_calling_agent(model, tools, agent_prompt)

        agent_executor = AgentExecutor(
            agent=agent_obj,
            tools=tools,
            verbose=False,
            max_iterations=10,
            max_execution_time=120,
            handle_parsing_errors=True,
            return_intermediate_steps=True
        )

        agent_with_history = RunnableWithMessageHistory(
            agent_executor,
            get_session_history,
            history_messages_key="chat_history",
        )

        max_attempts = 3
        for attempt in range(max_attempts):
            try:
                # Agent ì‹¤í–‰
                result = agent_with_history.invoke(
                    {
                        "input": state["question"],
                        "retrieved_data": state.get("context"),
                        "relevance": state.get("relevance"),
                        "session_id": session_id  # <-- session_id ëª…ì‹œì  ì „ë‹¬
                    },
                    {'configurable': {'session_id': session_id}}
                )

                # ê²°ê³¼ì—ì„œ ì½”ë“œ ì‹¤í–‰ì´ í•„ìš”í•˜ë©´ tools ë‚´ë¶€ì—ì„œ ìë™ í˜¸ì¶œë¨
                state['answer'] = result['output']
                return state

            except Exception as e_inner:
                print(f"âš ï¸ ì—ì´ì „íŠ¸ ì‹œë„ {attempt+1}/{max_attempts} ì‹¤íŒ¨: {e_inner}")
                if attempt == max_attempts - 1:
                    raise

    except Exception as e:
        print(f"âŒ ì—ì´ì „íŠ¸ ì‹¤í–‰ ìµœì¢… ì‹¤íŒ¨: {e}")
        state['answer'] = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)[:100]}"
        return state

########################################################################
############################ Workflow Graph ############################
########################################################################

workflow = StateGraph(GraphState)

workflow.add_node("Router", router)
workflow.add_node("Agent", agent)

workflow.add_edge("Router", "Agent")
workflow.add_edge("Agent", END)

workflow.set_entry_point("Router")

memory = MemorySaver()
graph = workflow.compile(checkpointer=memory)  


 ##############################################################################################################
################################################Chat Interface################################################
##############################################################################################################

from fastapi import FastAPI, Request, Form, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from pydantic_settings import BaseSettings
from functools import lru_cache


# ğŸ”§ ê°œì„  4: FastAPI ì•± ìƒì„± ì‹œ lifespan ì´ë²¤íŠ¸ ì¶”ê°€
@asynccontextmanager
async def lifespan(app: FastAPI):
    # ì‹œì‘ ì‹œ
    print("ğŸš€ ì„œë²„ ì‹œì‘")
    yield
    # ì¢…ë£Œ ì‹œ
    print("ğŸ›‘ ì„œë²„ ì¢…ë£Œ")

app = FastAPI(title="Juso Chatbot API", lifespan=lifespan)

class Settings(BaseSettings):
    OPENAI_API_KEY: str = os.getenv("OPENAI_API_KEY", "")
    ALLOWED_ORIGINS: list = [
        "http://localhost:3000",
        "http://localhost:3001", 
        "https://localhost:3000",
        "https://localhost:3001",
        "http://labs.datahub.kr",
        "https://labs.datahub.kr",
        "http://localhost:8000",
        "https://localhost:8000",
    ]

@lru_cache()
def get_settings():
    return Settings() 

settings = get_settings()

app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class MessageRequest(BaseModel):
    message: str
    session_id: str = None

class FeedbackRequest(BaseModel):
    score: float
    run_id: str

current_user_id = None

# ğŸ”§ ê°œì„  5: ë¹„ë™ê¸° ì²˜ë¦¬ ë° ìƒì„¸í•œ ì—ëŸ¬ í•¸ë“¤ë§
@app.post("/api/")
async def stream_responses(request: Request):
    try:
        data = await request.json()
        message = data.get('message')
        client_session_id = data.get('session_id')
        
        if not message:
            raise HTTPException(status_code=400, detail="Message is required")
        
        if not message.strip():
            raise HTTPException(status_code=400, detail="Message cannot be empty")

        # ë©”ì‹œì§€ ê¸¸ì´ ì œí•œ
        if len(message) > 1000:
            raise HTTPException(status_code=400, detail="Message too long (max 1000 characters)")

        # ì„¸ì…˜ ID ì²˜ë¦¬
        if not client_session_id:
            client_session_id = generate_session_id()

        # ğŸ”§ ê°œì„  6: ì„¤ì • ìµœì í™”
        config = RunnableConfig(
            recursion_limit=10,  # ì¬ê·€ ì œí•œ ì¤„ì„
            configurable={
                "thread_id": f"HIKE-FACTORY-CHATBOT-{client_session_id[:8]}", 
                "user_id": current_user_id, 
                "session_id": client_session_id
            }
        )

        inputs = GraphState(
            question=message,
            session_id=client_session_id,
            q_type='',
            context='',
            answer='',
            relevance='',
        )

        try:
            # íƒ€ì„ì•„ì›ƒ ì„¤ì •ìœ¼ë¡œ ë¬´í•œ ëŒ€ê¸° ë°©ì§€
            final_state = await asyncio.wait_for(
                asyncio.to_thread(graph.invoke, inputs, config),
                timeout=180  # 3ë¶„ íƒ€ì„ì•„ì›ƒ
            )
            
            answer_text = final_state["answer"]
            
            # ì‘ë‹µ ê²€ì¦
            if not answer_text or not isinstance(answer_text, str):
                answer_text = "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            # ì„¸ì…˜ í†µê³„
            current_history = get_session_history(client_session_id)
            message_count = len(current_history.messages)
            
            print(f"âœ… ì„¸ì…˜ {client_session_id[:8]}... ì‘ë‹µ ì™„ë£Œ (ì´ {message_count}ê°œ ë©”ì‹œì§€)")
            
            return {
                "answer": answer_text,
                "session_id": client_session_id,
                "message_count": message_count,
                "status": "success"
            }
            
        except asyncio.TimeoutError:
            print(f"â° íƒ€ì„ì•„ì›ƒ: {client_session_id[:8]}...")
            return {
                "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.",
                "session_id": client_session_id,
                "status": "timeout"
            }
        except GraphRecursionError as e:
            print(f"ğŸ”„ ì¬ê·€ ì œí•œ ì´ˆê³¼: {e}")
            return {
                "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ì´ ë„ˆë¬´ ë³µì¡í•©ë‹ˆë‹¤. ë” ê°„ë‹¨í•œ ì§ˆë¬¸ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.",
                "session_id": client_session_id,
                "status": "recursion_error"
            }
        except Exception as e:
            print(f"âŒ ê·¸ë˜í”„ ì‹¤í–‰ ì˜¤ë¥˜: {type(e).__name__}: {str(e)[:200]}")
            return {
                "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.",
                "session_id": client_session_id,
                "status": "error",
                "error_type": type(e).__name__
            }

    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ API ì˜¤ë¥˜: {type(e).__name__}: {str(e)}")
        raise HTTPException(status_code=500, detail="Internal server error")

@app.post("/api/reset")
async def reset_store(request: Request):
    try:
        data = await request.json()
        session_id_to_reset = data.get('session_id')
        
        if session_id_to_reset:
            # íŠ¹ì • ì„¸ì…˜ë§Œ ì´ˆê¸°í™”
            message_count = thread_safe_store.clear_session(session_id_to_reset)
            new_session_id = generate_session_id()
            
            print(f"ğŸ—‘ï¸ ì„¸ì…˜ ì‚­ì œ: {session_id_to_reset[:8]}... ({message_count}ê°œ ë©”ì‹œì§€)")
            
            return {
                "status": "Session reset successfully",
                "session_id": new_session_id,
                "cleared_messages": message_count
            }
        else:
            # ëª¨ë“  ì„¸ì…˜ ì´ˆê¸°í™”
            total_sessions, total_messages = thread_safe_store.clear_session()
            new_session_id = generate_session_id()
            
            print(f"ğŸ§¹ ì „ì²´ ì´ˆê¸°í™”: {total_sessions}ê°œ ì„¸ì…˜, {total_messages}ê°œ ë©”ì‹œì§€ ì‚­ì œ")
            
            return {
                "status": "All sessions reset successfully",
                "session_id": new_session_id,
                "cleared_sessions": total_sessions,
                "cleared_messages": total_messages
            }
            
    except Exception as e:
        print(f"âŒ ë¦¬ì…‹ ì˜¤ë¥˜: {e}")
        # ì˜¤ë¥˜ ë°œìƒì‹œì—ë„ ìƒˆ ì„¸ì…˜ ID ë°˜í™˜
        new_session_id = generate_session_id()
        
        return {
            "status": "Sessions reset due to error",
            "session_id": new_session_id,
            "error": str(e)
        }

# ğŸ”§ ê°œì„  7: í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
@app.get("/health")
async def health_check():
    stats = thread_safe_store.get_stats()
    return {
        "status": "healthy",
        "timestamp": time.time(),
        "sessions": stats['total_sessions'],
        "messages": stats['total_messages']
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "main:app", 
        host="0.0.0.0", 
        port=8000, 
        reload=True,
        workers=1,  # ë‹¨ì¼ ì›Œì»¤ë¡œ ë©”ëª¨ë¦¬ ê³µìœ  ë¬¸ì œ ë°©ì§€
        timeout_keep_alive=30,
        limit_concurrency=100,  # ë™ì‹œ ì—°ê²° ì œí•œ
        limit_max_requests=1000  # ìµœëŒ€ ìš”ì²­ ìˆ˜ ì œí•œ
    )