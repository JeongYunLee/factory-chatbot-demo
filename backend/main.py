import uuid, os, io, sys, time, json
from datetime import datetime, date
import asyncio
import threading
from contextlib import asynccontextmanager
from dotenv import load_dotenv
from typing import TypedDict, Annotated
import pandas as pd
import numpy as np
from functools import wraps

from openai import OpenAI
from langchain_openai import ChatOpenAI
# import chromadb
# from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings

from langchain_community.tools.tavily_search import TavilySearchResults

from langgraph.graph import END, StateGraph
from langgraph.checkpoint.memory import MemorySaver
from langgraph.errors import GraphRecursionError

from langchain_core.output_parsers import JsonOutputParser
from langchain_core.output_parsers.openai_tools import JsonOutputToolsParser
from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_core.prompts import PromptTemplate
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnableConfig  
from langchain_core.output_parsers import StrOutputParser

from langchain_community.chat_message_histories import ChatMessageHistory, StreamlitChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from langgraph.graph.message import add_messages
from operator import itemgetter

from langchain.agents import tool
from langchain.agents import create_tool_calling_agent
from langchain.agents import AgentExecutor

# from langchain_teddynote import logging
from langsmith import traceable
import threading

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv(override=True)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise ValueError("OPENAI_API_KEY not found in environment variables")

# ëª¨ë¸
model = ChatOpenAI(
    openai_api_key=OPENAI_API_KEY,
    model="gpt-5.1-2025-11-13",
    temperature=0
)

df = pd.read_csv('data/cleaned_ì „êµ­ê³µì¥ë“±ë¡í˜„í™©_preprocessed_seoul.csv')

###################################################################################################

class GraphState(TypedDict):
    question: str  # ì§ˆë¬¸
    q_type: str  # ì§ˆë¬¸ì˜ ìœ í˜•
    answer: str | list[str]  # llmì´ ìƒì„±í•œ ë‹µë³€
    session_id: str  # ì„¸ì…˜ ID
    context: str | None  # ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸
    relevance: str | None  # ê²€ìƒ‰ ì í•©ë„
    execution_id: str | None  # ì‹¤í–‰ ê²°ê³¼ ì‹ë³„ì

# ğŸ”§ ê°œì„  1: ìŠ¤ë ˆë“œ ì•ˆì „í•œ ì €ì¥ì†Œ
import threading
from collections import defaultdict

class ThreadSafeStore:
    def __init__(self):
        self._store = {}
        self._lock = threading.RLock()  # ì¬ì§„ì… ê°€ëŠ¥í•œ ë½
    
    def get_session_history(self, session_id: str):
        with self._lock:
            if session_id not in self._store:
                self._store[session_id] = ChatMessageHistory()
                print(f"ğŸ†• ìƒˆë¡œìš´ ì„¸ì…˜ íˆìŠ¤í† ë¦¬ ìƒì„±: {session_id[:8]}...")
            return self._store[session_id]
    
    def clear_session(self, session_id: str = None):
        with self._lock:
            if session_id:
                if session_id in self._store:
                    message_count = len(self._store[session_id].messages)
                    del self._store[session_id]
                    return message_count
                return 0
            else:
                total_sessions = len(self._store)
                total_messages = sum(len(history.messages) for history in self._store.values())
                self._store.clear()
                return total_sessions, total_messages
    
    def get_stats(self):
        with self._lock:
            return {
                'total_sessions': len(self._store),
                'total_messages': sum(len(history.messages) for history in self._store.values())
            }

# ì „ì—­ ìŠ¤ë ˆë“œ ì•ˆì „ ì €ì¥ì†Œ
thread_safe_store = ThreadSafeStore()

# ì„¸ì…˜ IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
def get_session_history(session_ids):
    return thread_safe_store.get_session_history(session_ids)

# ìƒˆë¡œìš´ ì„¸ì…˜ ID ìƒì„± í•¨ìˆ˜
def generate_session_id():
    return str(uuid.uuid4())


class ExecutionResultStore:
    """
    ì„¸ì…˜ë³„ ì‹¤í–‰ ê²°ê³¼ë¥¼ ì €ì¥í•˜ëŠ” ìŠ¤í† ì–´
    - key: execution_id
    - value: { execution_id, session_id, code, result, created_at }
    - ë³„ë„ ì¸ë±ìŠ¤ë¡œ session_id -> [execution_id, ...] ê´€ë¦¬
    """

    def __init__(self):
        self._store = {}
        self._session_index = {}  # session_id -> set(execution_id)
        self._lock = threading.RLock()

    def save(self, session_id: str, code: str | None, output, question: str = ""):
        execution_id = str(uuid.uuid4())
        payload = {
            "execution_id": execution_id,
            "session_id": session_id,
            "code": code,
            "result": serialize_execution_output(output, question),
            "created_at": time.time()
        }
        with self._lock:
            self._store[execution_id] = payload
            # ì„¸ì…˜ë³„ ì¸ë±ìŠ¤ì— execution_id ë“±ë¡
            if session_id not in self._session_index:
                self._session_index[session_id] = set()
            self._session_index[session_id].add(execution_id)
        return execution_id

    def get(self, execution_id: str):
        with self._lock:
            return self._store.get(execution_id)

    def clear_session(self, session_id: str | None = None):
        """
        íŠ¹ì • session_idì— í•´ë‹¹í•˜ëŠ” execution ê²°ê³¼ë§Œ ì‚­ì œí•˜ê±°ë‚˜,
        session_idê°€ ì—†ìœ¼ë©´ ì „ì²´ ì‹¤í–‰ ê²°ê³¼ë¥¼ ì‚­ì œ.
        """
        with self._lock:
            if session_id is None:
                self._store.clear()
                self._session_index.clear()
                return

            exec_ids = self._session_index.get(session_id)
            if not exec_ids:
                return

            for eid in exec_ids:
                self._store.pop(eid, None)
            self._session_index.pop(session_id, None)


def ensure_json_serializable(value):
    if isinstance(value, (np.integer, np.int32, np.int64)):
        return int(value)
    if isinstance(value, (np.floating, np.float32, np.float64)):
        return float(value)
    if isinstance(value, (np.bool_,)):
        return bool(value)
    if isinstance(value, (list, tuple)):
        return [ensure_json_serializable(v) for v in value]
    if isinstance(value, dict):
        return {k: ensure_json_serializable(v) for k, v in value.items()}
    if isinstance(value, (pd.Timestamp,)):
        return value.isoformat()
    if isinstance(value, np.datetime64):
        return pd.Timestamp(value).isoformat()
    if isinstance(value, (datetime, date)):
        return value.isoformat()
    if pd.isna(value):
        return None
    return value


def dataframe_to_rows(df: pd.DataFrame, limit: int = 50):
    preview_df = df.head(limit).copy()
    preview_df = preview_df.where(pd.notnull(preview_df), None)
    records = preview_df.to_dict(orient="records")
    return [ensure_json_serializable(record) for record in records]


class VisualizationRecommendation(BaseModel):
    chart_type: str = Field(description="Recommended chart type. Choose from ['bar_chart', 'line_chart', 'pie_chart', 'map', 'heatmap', 'scatter_plot', 'none']")
    x_axis: str | None = Field(default=None, description="Column name for x-axis")
    y_axis: str | None = Field(default=None, description="Column name for y-axis")
    orientation: str | None = Field(default=None, description="For bar chart: 'horizontal' or 'vertical'")
    has_location: bool = Field(default=False, description="Whether the data contains location information suitable for map visualization")
    group_by: str | None = Field(default=None, description="Column name for grouping data")
    time_series: bool = Field(default=False, description="Whether the data is time-series data")

visualization_output_parser = JsonOutputParser(pydantic_object=VisualizationRecommendation)
visualization_format_instructions = visualization_output_parser.get_format_instructions()

visualization_prompt = PromptTemplate(
    template="""
    You are an expert data visualization analyst. Analyze the user's question and the data structure to recommend the best visualization type.

    Available chart types:
    - 'bar_chart': For comparing categories (e.g., "êµ¬ë³„ ê³µì¥ ìˆ˜", "ì—…ì¢…ë³„ ì§ì› ìˆ˜")
    - 'line_chart': For showing trends over time (e.g., "ì—°ë„ë³„ ë“±ë¡ ê±´ìˆ˜ ì¶”ì´", "ìµœê·¼ 5ë…„ê°„ ë³€í™”")
    - 'pie_chart': For showing proportions/percentages (e.g., "ì—…ì¢…ë³„ ë¹„ìœ¨", "ê·œëª¨ë³„ ë¶„í¬")
    - 'map': For location-based data (e.g., "êµ¬ë³„ ê³µì¥ ë¶„í¬", "ì§€ì—­ë³„ ë¶„ì„")
    - 'heatmap': For 2D cross-tabulation (e.g., "êµ¬ë³„ ì—…ì¢…ë³„ ê³µì¥ ìˆ˜")
    - 'scatter_plot': For correlation between two numeric variables (e.g., "ë©´ì  ëŒ€ë¹„ ì§ì› ìˆ˜")
    - 'none': When visualization is not suitable or data is too complex

    Data columns available: {columns}
    User question: {question}
    Data sample (first 3 rows): {sample_data}

    Consider:
    1. If the question mentions location (êµ¬, ì‹œêµ°êµ¬, ì§€ì—­, ì§€ë„), recommend 'map' if location columns exist
    2. If the question mentions time/trend (ì¶”ì´, ë³€í™”, ì—°ë„, ë…„ë„), recommend 'line_chart'
    3. If the question asks for comparison (ë¹„êµ, ìƒìœ„, ë§ë‹¤), recommend 'bar_chart'
    4. If the question asks for proportion/ratio (ë¹„ìœ¨, ë¶„í¬), recommend 'pie_chart'
    5. If data has 2 categorical dimensions, consider 'heatmap'
    6. If data has 2 numeric variables for correlation, consider 'scatter_plot'

    {format_instructions}
    """,
    input_variables=["question", "columns", "sample_data"],
    partial_variables={"format_instructions": visualization_format_instructions},
)


def infer_visualization_type(question: str, output) -> dict | None:
    """
    ì§ˆë¬¸ê³¼ ê²°ê³¼ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì‹œê°í™” íƒ€ì…ì„ ì¶”ë¡ í•©ë‹ˆë‹¤.
    """
    try:
        # DataFrame ë˜ëŠ” Seriesì¸ ê²½ìš°ì—ë§Œ ì‹œê°í™” ì¶”ë¡ 
        if not isinstance(output, (pd.DataFrame, pd.Series)):
            return None
        
        # Seriesë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
        if isinstance(output, pd.Series):
            df_for_analysis = output.reset_index()
        else:
            df_for_analysis = output.copy()
        
        # ë°ì´í„°ê°€ ë¹„ì–´ìˆìœ¼ë©´ None ë°˜í™˜
        if len(df_for_analysis) == 0:
            return None
        
        # ì»¬ëŸ¼ì´ ë„ˆë¬´ ë§ìœ¼ë©´ ì‹œê°í™” ë¹„ì¶”ì²œ
        if len(df_for_analysis.columns) > 10:
            return {"chart_type": "none"}
        
        # ìƒ˜í”Œ ë°ì´í„° ì¤€ë¹„ (ìµœëŒ€ 3í–‰)
        sample_df = df_for_analysis.head(3)
        sample_data = sample_df.to_dict(orient="records")
        
        # ì»¬ëŸ¼ ëª©ë¡
        columns = list(df_for_analysis.columns)
        
        # LLMì„ ì‚¬ìš©í•˜ì—¬ ì‹œê°í™” íƒ€ì… ì¶”ë¡ 
        chain = visualization_prompt | model | visualization_output_parser
        
        # ì½œë°± ë¹„í™œì„±í™”í•˜ì—¬ RootListenersTracer ì—ëŸ¬ ë°©ì§€
        config = RunnableConfig(callbacks=[])
        result = chain.invoke(
            {
                "question": question,
                "columns": str(columns),
                "sample_data": str(sample_data)
            },
            config=config
        )
        
        # ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        visualization_meta = {
            "chart_type": result.get("chart_type", "none"),
            "x_axis": result.get("x_axis"),
            "y_axis": result.get("y_axis"),
            "orientation": result.get("orientation", "vertical"),
            "has_location": result.get("has_location", False),
            "group_by": result.get("group_by"),
            "time_series": result.get("time_series", False)
        }
        
        # ì‹¤ì œ ë°ì´í„° êµ¬ì¡°ì— ë§ê²Œ ì¶• ì •ë³´ ë³´ì •
        if visualization_meta["chart_type"] != "none":
            # x_axisê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ê³  DataFrameì¸ ê²½ìš° ì²« ë²ˆì§¸ ì»¬ëŸ¼ ì‚¬ìš©
            if not visualization_meta["x_axis"] and len(columns) > 0:
                if isinstance(output, pd.Series):
                    visualization_meta["x_axis"] = "index"
                    visualization_meta["y_axis"] = "value"
                else:
                    # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì´ ì¸ë±ìŠ¤ ì»¬ëŸ¼ì¸ ê²½ìš°
                    if columns[0] in ["index", "ì •ì œ_ì‹œêµ°êµ¬ëª…", "ì •ì œ_ì—…ì¢…ëª…"]:
                        visualization_meta["x_axis"] = columns[0]
                    # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ì°¾ê¸°
                    numeric_cols = df_for_analysis.select_dtypes(include=[np.number]).columns.tolist()
                    if numeric_cols:
                        visualization_meta["y_axis"] = numeric_cols[0]
            
            # ìœ„ì¹˜ ì •ë³´ í™•ì¸
            location_cols = [col for col in columns if any(keyword in col for keyword in ["ì‹œêµ°êµ¬", "ì‹œë„", "êµ¬", "ì§€ì—­", "ì£¼ì†Œ"])]
            if location_cols:
                visualization_meta["has_location"] = True
                if not visualization_meta["x_axis"]:
                    visualization_meta["x_axis"] = location_cols[0]
        
        return visualization_meta
        
    except Exception as e:
        print(f"âš ï¸ ì‹œê°í™” íƒ€ì… ì¶”ë¡  ì‹¤íŒ¨: {e}")
        return None


def serialize_execution_output(output, question: str = ""):
    # ì‹œê°í™” ë©”íƒ€ë°ì´í„° ì¶”ë¡ 
    visualization_meta = infer_visualization_type(question, output) if question else None
    
    if isinstance(output, pd.DataFrame):
        result = {
            "type": "table",
            "columns": list(output.columns),
            "rows": dataframe_to_rows(output),
            "row_count": int(len(output))
        }
        if visualization_meta:
            result["visualization"] = visualization_meta
        return result
    if isinstance(output, pd.Series):
        series_df = output.reset_index()
        series_df.columns = ["index", "value"]
        result = {
            "type": "table",
            "columns": list(series_df.columns),
            "rows": dataframe_to_rows(series_df),
            "row_count": int(len(output))
        }
        if visualization_meta:
            result["visualization"] = visualization_meta
        return result
    if isinstance(output, (list, tuple)):
        return {
            "type": "list",
            "rows": [ensure_json_serializable(item) for item in output],
            "row_count": len(output)
        }
    if isinstance(output, dict):
        return {
            "type": "object",
            "data": ensure_json_serializable(output)
        }
    if output is None:
        return {
            "type": "text",
            "value": None
        }
    return {
        "type": "text",
        "value": str(output)
    }


execution_store = ExecutionResultStore()

#######################################################################
############################ nodes: Router ############################
#######################################################################

class Router(BaseModel):
    type: str = Field(description="type of the query that model choose. Choose from ['general', 'domain_specific']")

router_output_parser = JsonOutputParser(pydantic_object=Router)
router_format_instructions = router_output_parser.get_format_instructions()

router_prompt = PromptTemplate(
    template="""
            You are an expert who classifies the type of question. There are two query types: ['general', 'domain_specific']

            [general]
            Questions unrelated to data query, such as translating English to Korean, asking for general knowledge (e.g., "What is the capital of South Korea?"), or queries that can be answered through a web search.

            [domain_specific]
            Questions related to 'factory' or 'company' domain and data query, such as 'count the unique values of factories in Seoul', or count 'the number of rows in a table'.

            <Output format>: Always respond with either "general" or "domain_specific" and nothing else. {format_instructions}
            <chat_history>: {chat_history}
            
            <Question>: {query} 
            """,
    input_variables=["query", "chat_history"],
    partial_variables={"format_instructions": router_format_instructions},
)

def router(state: GraphState) -> GraphState:
    # ë””ë²„ê¹…: Routerì—ì„œ ë°›ì€ ì§ˆë¬¸ í™•ì¸
    question = state["question"]
    print(f"ğŸ”€ Router ì…ë ¥ ì§ˆë¬¸ ê¸¸ì´: {len(question)}, ë 5ì: {repr(question[-5:]) if len(question) >= 5 else repr(question)}")
    
    chain = router_prompt | model | router_output_parser
    
    router_with_history  = RunnableWithMessageHistory(
        chain,
        get_session_history,
        input_messages_key="query",
        history_messages_key="chat_history",
    )
    
    # ì½œë°± ë¹„í™œì„±í™”í•˜ì—¬ RootListenersTracer ì—ëŸ¬ ë°©ì§€
    # router_with_history.invoke()ê°€ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•˜ëŠ”ë°, 
    # LangChain ì½œë°± ì‹œìŠ¤í…œì´ ì´ë¥¼ ì¶”ì í•˜ë ¤ê³  í•  ë•Œ ì—ëŸ¬ ë°œìƒ
    config = RunnableConfig(
        configurable={'session_id': state["session_id"]},
        callbacks=[]  # ì½œë°± ë¹„í™œì„±í™”
    )
    router_result = router_with_history.invoke(
        {"query": question}, 
        config
    )
    state["q_type"] = router_result['type']
    return state

def router_conditional_edge(state: GraphState) -> GraphState:
    q_type = state["q_type"].strip()
    return q_type

##################################################################################
###################### nodes: Generate Python Pandas Code ########################
##################################################################################

class CodeGenerator(BaseModel):
    code: str = Field(description="Python Pandas Code")

code_generator_output_parser = JsonOutputParser(pydantic_object=CodeGenerator)
code_generator_format_instructions = code_generator_output_parser.get_format_instructions()

code_generator_prompt = PromptTemplate(
    template="""
            You are an expert who can generate Python Pandas Code to answer the query.

            Write the code with the following dataset metadata. Do not use any other columns except the ones provided in the metadata. The columns are written in Korean.

            <Dataset Metadata>: 
            # Basic Information
            1. 'ê³µì¥ê´€ë¦¬ë²ˆí˜¸' (Factory Management Number): Unique factory identification number. [Important] A single factory management number can appear across multiple rows. When counting the number of factories, always use unique/distinct values of this field.

            # Company & Factory Information
            2. 'íšŒì‚¬ëª…' (Company Name): Name of the company operating the factory. It's not unique. 
            3. 'ê³µì¥êµ¬ë¶„' (Factory Classification): Type/classification of the factory. categorized by 
            4. 'ë‹¨ì§€ëª…' (Complex Name): Name of the industrial complex (if applicable)
            5. 'ì„¤ë¦½êµ¬ë¶„' (Establishment Type): Classification of how the factory was established
            6. 'ì…ì£¼í˜•íƒœ' (Occupancy Type): Type of occupancy arrangement
            7. 'ë“±ë¡êµ¬ë¶„' (Registration Type): Classification of factory registration
            8. 'ì „í™”ë²ˆí˜¸' (Phone Number): Contact phone number


            # Employee Statistics
            9. 'ë‚¨ìì¢…ì—…ì›' (Male Employees): Number of male employees
            10. 'ì—¬ìì¢…ì—…ì›' (Female Employees): Number of female employees
            11. 'ì™¸êµ­ì¸ë‚¨ìì¢…ì—…ì›' (Foreign Male Employees): Number of foreign male employees
            12. 'ì™¸êµ­ì¸ì—¬ìì¢…ì—…ì›' (Foreign Female Employees): Number of foreign female employees
            13. 'ì¢…ì—…ì›í•©ê³„' (Total Employees): Total number of employees

            # Production Information
            14. 'ìƒì‚°í’ˆ' (Products): Products manufactured at the factory. It's not categorized and normalized, so you need use 'str.contains' to filter the products.
            15. 'ì›ìì¬' (Raw Materials): Raw materials used in production. It's not categorized and normalized, so you need use 'str.contains' to filter the products.
            16. 'ê³µì¥ê·œëª¨' (Factory Scale): Size classification of the factory. e.g. ['ì†Œê¸°ì—…', 'ì¤‘ê¸°ì—…', 'ëŒ€ê¸°ì—…', 'ì¤‘ê²¬ê¸°ì—…']
            
            # Facility Specifications
            17. 'ìš©ì§€ë©´ì ' (Land Area): Total land area in square meters
            18. 'ì œì¡°ì‹œì„¤ë©´ì ' (Manufacturing Facility Area): Area dedicated to manufacturing facilities
            19. 'ë¶€ëŒ€ì‹œì„¤ë©´ì ' (Auxiliary Facility Area): Area of auxiliary/support facilities
            20. 'ê±´ì¶•ë©´ì ' (Building Area): Total building area
            21. 'ì§€ì‹ì‚°ì—…ì„¼í„°ëª…' (Knowledge Industry Center Name): Name of knowledge industry center (if applicable)

            # Location & Administrative
            22. 'í•„ì§€ìˆ˜' (Number of Parcels): Number of land parcels
            23. 'ê³µì¥ê´€ë¦¬ë²ˆí˜¸' (Factory Management Number): Unique factory identification number

            #Standardized Fields (ì •ì œ_)
            24. 'ì •ì œ_ê´€ë¦¬ê¸°ê´€' (Standardized Management Agency): Standardized name of the management agency 
            25. 'ì •ì œ_ë³´ìœ êµ¬ë¶„' (Standardized Ownership Type): Standardized ownership classification
            26. 'ì •ì œ_ì‹œêµ°êµ¬ëª…' (Standardized District Name): Standardized city/county/district name
            27. 'ì •ì œ_ì‹œë„ëª…' (Standardized Province Name): Standardized province/metropolitan city name
            28. 'ì •ì œ_ì—…ì¢…ëª…' (Standardized Industry Name): Standardized industry name. It's not unique, so you need to calculate with 'ì •ì œ_ëŒ€í‘œì—…ì¢…' and show in 'ì •ì œ_ì—…ì¢…ëª…'
            29. 'ì •ì œ_ëŒ€í‘œì—…ì¢…' (Standardized Primary Industry): Standardized primary industry classification. It's in code, so after use it, you need to show the name using 'ì •ì œ_ì—…ì¢…ëª…' column. For example, if 'ì •ì œ_ëŒ€í‘œì—…ì¢…' is 'a11', you need to show the name using 'ì œì¡°ì—…' column.
            29. 'ì •ì œ_ìš©ë„ì§€ì—­' (Standardized Zoning District): Standardized zoning/land use district
            30. 'ì •ì œ_ì§€ëª©' (Standardized Land Category): Standardized land category classification

            # Date Fields
            31. 'ì •ì œ_ìµœì´ˆë“±ë¡ì¼' (Standardized Initial Registration Date): Standardized date of initial registration (format: YYYY-MM-DD)
            32. 'ì •ì œ_ìµœì´ˆìŠ¹ì¸ì¼' (Standardized Initial Approval Date): Standardized date of initial approval (format: YYYY-MM-DD)

            Write the code with the most efficient way.
            <Output format>: Always respond with Python Pandas code. Always assign the final result to a variable called `return_var`. Do not use print(). {format_instructions}
            <chat_history>: {chat_history}
            
            <Question>: {query} 
            """,
    input_variables=["query", "chat_history"],
    partial_variables={"format_instructions": code_generator_format_instructions},
)

@tool
def code_generator(input, session_id: str | None = None):
    """
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ CSVì—ì„œ ì¿¼ë¦¬í•  ìˆ˜ ìˆëŠ” Python Pandas ì½”ë“œë¥¼ ì‘ì„±í•˜ëŠ” ë„êµ¬
    """
    # ë””ë²„ê¹…: code_generatorì— ì „ë‹¬ëœ ì…ë ¥ í™•ì¸
    print(f"ğŸ“ code_generator ì…ë ¥ ê¸¸ì´: {len(input)}, ë 5ì: {repr(input[-5:]) if len(input) >= 5 else repr(input)}")
    
    chain = code_generator_prompt | model | code_generator_output_parser

    resolved_session_id = session_id or generate_session_id()

    code_generator_with_history = RunnableWithMessageHistory(
        chain,
        get_session_history,
        input_messages_key="query",
        history_messages_key="chat_history",
    )

    # ì½œë°± ë¹„í™œì„±í™”í•˜ì—¬ RootListenersTracer ì—ëŸ¬ ë°©ì§€
    config = RunnableConfig(
        configurable={'session_id': resolved_session_id},
        callbacks=[]  # ì½œë°± ë¹„í™œì„±í™”
    )
    code_generator_result = code_generator_with_history.invoke(
        {"query": input},  # ì›ë³¸ input ê·¸ëŒ€ë¡œ ì „ë‹¬
        config
    )
    return code_generator_result['code']

@tool
def code_executor(input_code: str, max_retries=5):
    """
    LLMì´ ìƒì„±í•œ Pandas ì½”ë“œë¥¼ ì•ˆì „í•˜ê²Œ ì‹¤í–‰í•˜ê³  return_var ë°˜í™˜.
    dfëŠ” ê¸€ë¡œë²Œ ë³€ìˆ˜ ì‚¬ìš©.
    NA, None, 0 ë“±ì˜ ì—ëŸ¬ ëŒ€ë¹„.
    """
    global df
    local_vars = {'df': df}

    for attempt in range(max_retries):
        try:
            exec(input_code, local_vars)
            if 'return_var' not in local_vars:
                raise ValueError("Generated code did not assign value to 'return_var'.")
            return local_vars['return_var']
        except Exception as e:
            print(f"âš ï¸ ì½”ë“œ ì‹¤í–‰ ì‹¤íŒ¨ (ì‹œë„ {attempt+1}/{max_retries}): {e}")
            # NAë‚˜ boolean ë¹„êµ ì—ëŸ¬ ë“± ì¬ì‹œë„ ê°€ëŠ¥
            if attempt == max_retries - 1:
                raise

############################ tools & Agents ############################

# ğŸ”§ ê°œì„  3: OpenAI API ë ˆì´íŠ¸ ë¦¬ë¯¸íŒ… ë° ì¬ì‹œë„
import openai
from openai import RateLimitError, APITimeoutError

def retry_on_failure(max_retries=3, delay=1):
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            last_exception = None
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    last_exception = e
                    if attempt < max_retries - 1:
                        print(f"âš ï¸ ì‹œë„ {attempt + 1} ì‹¤íŒ¨, {delay}ì´ˆ í›„ ì¬ì‹œë„: {str(e)[:100]}")
                        time.sleep(delay * (attempt + 1))  # ì§€ìˆ˜ ë°±ì˜¤í”„
                    else:
                        print(f"âŒ ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨: {str(e)}")
            raise last_exception
        return wrapper
    return decorator

@retry_on_failure(max_retries=3, delay=2)
def call_openai_with_retry(client, **kwargs):
    try:
        return client.chat.completions.create(**kwargs)
    except RateLimitError as e:
        print(f"âš ï¸ OpenAI ë ˆì´íŠ¸ ë¦¬ë¯¸íŠ¸: {e}")
        time.sleep(5)  # ë ˆì´íŠ¸ ë¦¬ë¯¸íŠ¸ ì‹œ ë” ì˜¤ë˜ ëŒ€ê¸°
        raise
    except APITimeoutError as e:
        print(f"âš ï¸ OpenAI íƒ€ì„ì•„ì›ƒ: {e}")
        raise
    except Exception as e:
        print(f"âš ï¸ OpenAI API ì˜¤ë¥˜: {e}")
        raise
    
tools = [code_generator, code_executor]

def capture_execution_snapshot(session_id: str, intermediate_steps, question: str = "") -> str | None:
    if not intermediate_steps:
        return None

    code_snippet = None
    execution_output = None

    for step in intermediate_steps:
        try:
            action, observation = step
        except (TypeError, ValueError):
            continue

        tool_name = getattr(action, "tool", None)

        if tool_name == "code_generator" and isinstance(observation, str):
            code_snippet = observation
        elif tool_name == "code_executor":
            execution_output = observation

    if execution_output is None:
        return None

    return execution_store.save(session_id, code_snippet, execution_output, question)

agent_prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You are a helpful assistant that answers ONLY in Korean. "
            "You must follow these rules:\n"
            "1. If q_type is 'domain_specific', you MUST use tools to generate code and execute it."
            "2. Use the result of code_executor, which is called 'return_var', to answer."
            "3. ONLY if 'return_var' is empty ([], None, or pd.DataFrame with no rows), respond with 'ì°¸ì¡°í•  ì •ë³´ê°€ ì—†ì–´ì„œ ë‹µë³€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'"
            "4. Otherwise, ALWAYS use 'return_var' as the basis of your answer, and you MUST ADD '[DATA]' prefix at the beginning of the answer."
            "5. When you use Koean text, be careful about the encoding and code(e.g. '(ì£¼)' & 'ãˆœ' --> '(ì£¼)' is correct.)"
            "6. When you use number, be careful about the type (e.g. 114, '114') When you can't get the result, retry with other type."
            "7. After collect the data results, describe the data specifically and explain about the results for the user."
            "Always answer in Korean, never in English."
        ),
        ("placeholder", "{chat_history}"),
        ("human", "{input}"),
        ("human", "{retrieved_data}"),
        ("placeholder", "{agent_scratchpad}"),
    ]
)

def agent(state: GraphState) -> GraphState:
    """
    Agent ì‹¤í–‰ í•¨ìˆ˜
    - domain_specific ì§ˆë¬¸ì€ tools(code_generator + safe_code_executor) ì‚¬ìš©
    - code ì‹¤í–‰ ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ êµ¬ì¡° ì ìš©
    """
    session_id = state["session_id"]
    question = state["question"]
    
    # ë””ë²„ê¹…: Agentì—ì„œ ë°›ì€ ì§ˆë¬¸ í™•ì¸
    # print(f"ğŸ¤– Agent ì…ë ¥ ì§ˆë¬¸ ê¸¸ì´: {len(question)}, ë 5ì: {repr(question[-5:]) if len(question) >= 5 else repr(question)}")
    
    # chat_history = get_session_history(session_id)
    # chat_history.add_user_message(f"question: {question}, q_type: {state['q_type']}")

    try:
        # Agent ìƒì„±
        agent_obj = create_tool_calling_agent(model, tools, agent_prompt)

        agent_executor = AgentExecutor(
            agent=agent_obj,
            tools=tools,
            verbose=False,
            max_iterations=10,
            max_execution_time=120,
            handle_parsing_errors=True,
            return_intermediate_steps=True
        )

        agent_with_history = RunnableWithMessageHistory(
            agent_executor,
            get_session_history,
            history_messages_key="chat_history",
        )

        max_attempts = 5
        for attempt in range(max_attempts):
            try:
                # Agent ì‹¤í–‰ - ì›ë³¸ ì§ˆë¬¸ ê·¸ëŒ€ë¡œ ì „ë‹¬
                input_data = {
                    "input": question,  # state["question"] ëŒ€ì‹  ë³€ìˆ˜ ì‚¬ìš©
                    "retrieved_data": state.get("context"),
                    "relevance": state.get("relevance"),
                    "session_id": session_id  # <-- session_id ëª…ì‹œì  ì „ë‹¬
                }
                print(f"ğŸš€ Agent invoke ì…ë ¥ ë°ì´í„°ì˜ input ê¸¸ì´: {len(input_data['input'])}, ë 5ì: {repr(input_data['input'][-5:]) if len(input_data['input']) >= 5 else repr(input_data['input'])}")
                
                # ì½œë°± ë¹„í™œì„±í™”í•˜ì—¬ RootListenersTracer ì—ëŸ¬ ë°©ì§€
                config = RunnableConfig(
                    configurable={'session_id': session_id},
                    callbacks=[]  # ì½œë°± ë¹„í™œì„±í™”
                )
                result = agent_with_history.invoke(
                    input_data,
                    config
                )

                # ê²°ê³¼ì—ì„œ ì½”ë“œ ì‹¤í–‰ì´ í•„ìš”í•˜ë©´ tools ë‚´ë¶€ì—ì„œ ìë™ í˜¸ì¶œë¨
                state['answer'] = result['output']
                state['execution_id'] = capture_execution_snapshot(session_id, result.get('intermediate_steps'), state['question'])
                return state

            except Exception as e_inner:
                print(f"âš ï¸ ì—ì´ì „íŠ¸ ì‹œë„ {attempt+1}/{max_attempts} ì‹¤íŒ¨: {e_inner}")
                if attempt == max_attempts - 1:
                    raise

    except Exception as e:
        print(f"âŒ ì—ì´ì „íŠ¸ ì‹¤í–‰ ìµœì¢… ì‹¤íŒ¨: {e}")
        state['answer'] = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ì°½ì—ì„œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."
        return state

########################################################################
############################ Workflow Graph ############################
########################################################################

workflow = StateGraph(GraphState)

workflow.add_node("Router", router)
workflow.add_node("Agent", agent)

workflow.add_edge("Router", "Agent")
workflow.add_edge("Agent", END)

workflow.set_entry_point("Router")

memory = MemorySaver()
graph = workflow.compile(checkpointer=memory)  


##############################################################################################################
################################################Chat Interface################################################
##############################################################################################################

from fastapi import FastAPI, Request, Form, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from pydantic_settings import BaseSettings
from functools import lru_cache


# ğŸ”§ ê°œì„  4: FastAPI ì•± ìƒì„± ì‹œ lifespan ì´ë²¤íŠ¸ ì¶”ê°€
@asynccontextmanager
async def lifespan(app: FastAPI):
    # ì‹œì‘ ì‹œ
    print("ğŸš€ ì„œë²„ ì‹œì‘")
    yield
    # ì¢…ë£Œ ì‹œ
    print("ğŸ›‘ ì„œë²„ ì¢…ë£Œ")

app = FastAPI(
    title="Data Chatbot API",
    lifespan=lifespan,
    root_path="/projects/data-chatbot"
)

class Settings(BaseSettings):
    OPENAI_API_KEY: str = os.getenv("OPENAI_API_KEY", "")
    ALLOWED_ORIGINS: list = [
        "http://localhost:3000",
        "http://localhost:3001", 
        "https://localhost:3000",
        "https://localhost:3001",
        "http://labs.datahub.kr",
        "https://labs.datahub.kr",
        "http://localhost:8000",
        "https://localhost:8000",
        "http://localhost:86",
        "https://localhost:86",
    ]

@lru_cache()
def get_settings():
    return Settings() 

settings = get_settings()

app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class MessageRequest(BaseModel):
    message: str
    session_id: str = None

class FeedbackRequest(BaseModel):
    score: float
    run_id: str

current_user_id = None

# ğŸ”§ ê°œì„  5: ë¹„ë™ê¸° ì²˜ë¦¬ ë° ìƒì„¸í•œ ì—ëŸ¬ í•¸ë“¤ë§
@app.post("/api/")
async def stream_responses(request: Request):
    try:
        data = await request.json()
        message = data.get('message')
        client_session_id = data.get('session_id')
        
        if not message:
            raise HTTPException(status_code=400, detail="Message is required")
        
        # ê²€ì¦ë§Œ strip()ìœ¼ë¡œ ì²´í¬í•˜ê³ , ì‹¤ì œ ì‚¬ìš©í•  ë©”ì‹œì§€ëŠ” ì›ë³¸ ì‚¬ìš© (ëì˜ ë¹ˆ ìŠ¤í˜ì´ìŠ¤ ë³´ì¡´)
        if not message.strip():
            raise HTTPException(status_code=400, detail="Message cannot be empty")

        # ë©”ì‹œì§€ ê¸¸ì´ ì œí•œ
        if len(message) > 1000:
            raise HTTPException(status_code=400, detail="Message too long (max 1000 characters)")

        # ë””ë²„ê¹…: ë©”ì‹œì§€ ì›ë³¸ ê¸¸ì´ ë° ë ë¬¸ì í™•ì¸
        print(f"ğŸ“ ìˆ˜ì‹  ë©”ì‹œì§€ ê¸¸ì´: {len(message)}, ë ë¬¸ì: {repr(message[-5:]) if len(message) >= 5 else repr(message)}")
        print(f"ğŸ“ ì „ì²´ ë©”ì‹œì§€: {repr(message)}")
        
        # ë©”ì‹œì§€ ëì— ë¹ˆ ìŠ¤í˜ì´ìŠ¤ê°€ ì—†ìœ¼ë©´ ì¶”ê°€ (ë§ˆì§€ë§‰ ê¸€ì ë³´í˜¸)
        if not message.endswith(' '):
            message = message + ' '
            print(f"ğŸ”’ ë©”ì‹œì§€ ëì— ë³´í˜¸ ìŠ¤í˜ì´ìŠ¤ ì¶”ê°€: {repr(message[-5:])}")

        # ì„¸ì…˜ ID ì²˜ë¦¬
        if not client_session_id:
            client_session_id = generate_session_id()

        # ğŸ”§ ê°œì„  6: ì„¤ì • ìµœì í™”
        config = RunnableConfig(
            recursion_limit=10,  # ì¬ê·€ ì œí•œ ì¤„ì„
            configurable={
                "thread_id": f"HIKE-FACTORY-CHATBOT-{client_session_id[:8]}", 
                "user_id": current_user_id, 
                "session_id": client_session_id
            }
        )

        # ì›ë³¸ ë©”ì‹œì§€ ì‚¬ìš© (ëì˜ ë¹ˆ ìŠ¤í˜ì´ìŠ¤ í¬í•¨í•˜ì—¬ ë§ˆì§€ë§‰ ê¸€ì ëˆ„ë½ ë°©ì§€)
        inputs = GraphState(
            question=message,  # ë³´í˜¸ ìŠ¤í˜ì´ìŠ¤ê°€ ì¶”ê°€ëœ ë©”ì‹œì§€
            session_id=client_session_id,
            q_type='',
            context='',
            answer='',
            relevance='',
            execution_id=None,
        )

        try:
            # íƒ€ì„ì•„ì›ƒ ì„¤ì •ìœ¼ë¡œ ë¬´í•œ ëŒ€ê¸° ë°©ì§€
            final_state = await asyncio.wait_for(
                asyncio.to_thread(graph.invoke, inputs, config),
                timeout=180  # 3ë¶„ íƒ€ì„ì•„ì›ƒ
            )
            
            answer_text = final_state["answer"]
            
            # ì‘ë‹µ ê²€ì¦
            if not answer_text or not isinstance(answer_text, str):
                answer_text = "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            # ì„¸ì…˜ í†µê³„
            current_history = get_session_history(client_session_id)
            message_count = len(current_history.messages)
            
            print(f"âœ… ì„¸ì…˜ {client_session_id[:8]}... ì‘ë‹µ ì™„ë£Œ (ì´ {message_count}ê°œ ë©”ì‹œì§€)")
            
            return {
                "answer": answer_text,
                "session_id": client_session_id,
                "message_count": message_count,
                "status": "success",
                "execution_id": final_state.get("execution_id")
            }
            
        except asyncio.TimeoutError:
            print(f"â° íƒ€ì„ì•„ì›ƒ: {client_session_id[:8]}...")
            return {
                "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.",
                "session_id": client_session_id,
                "status": "timeout"
            }
        except GraphRecursionError as e:
            print(f"ğŸ”„ ì¬ê·€ ì œí•œ ì´ˆê³¼: {e}")
            return {
                "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ì´ ë„ˆë¬´ ë³µì¡í•©ë‹ˆë‹¤. ë” ê°„ë‹¨í•œ ì§ˆë¬¸ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.",
                "session_id": client_session_id,
                "status": "recursion_error"
            }
        except Exception as e:
            print(f"âŒ ê·¸ë˜í”„ ì‹¤í–‰ ì˜¤ë¥˜: {type(e).__name__}: {str(e)[:200]}")
            return {
                "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.",
                "session_id": client_session_id,
                "status": "error",
                "error_type": type(e).__name__
            }

    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ API ì˜¤ë¥˜: {type(e).__name__}: {str(e)}")
        raise HTTPException(status_code=500, detail="Internal server error")


@app.get("/api/execution/{execution_id}")
async def get_execution_result(execution_id: str):
    record = execution_store.get(execution_id)
    if not record:
        raise HTTPException(status_code=404, detail="Execution result not found")
    return record

@app.post("/api/reset")
async def reset_store(request: Request):
    try:
        data = await request.json()
        session_id_to_reset = data.get('session_id')

        if session_id_to_reset:
            # íŠ¹ì • ì„¸ì…˜ë§Œ ì´ˆê¸°í™”
            message_count = thread_safe_store.clear_session(session_id_to_reset)
            # í•´ë‹¹ ì„¸ì…˜ì˜ ì‹¤í–‰ ê²°ê³¼ë„ í•¨ê»˜ ì‚­ì œ
            execution_store.clear_session(session_id_to_reset)
            new_session_id = generate_session_id()

            print(f"ğŸ—‘ï¸ ì„¸ì…˜ ì‚­ì œ: {session_id_to_reset[:8]}... ({message_count}ê°œ ë©”ì‹œì§€)")

            return {
                "status": "Session reset successfully",
                "session_id": new_session_id,
                "cleared_messages": message_count
            }
        else:
            # ëª¨ë“  ì„¸ì…˜ ì´ˆê¸°í™”
            total_sessions, total_messages = thread_safe_store.clear_session()
            # ëª¨ë“  ì‹¤í–‰ ê²°ê³¼ ì´ˆê¸°í™”
            execution_store.clear_session()
            new_session_id = generate_session_id()

            print(f"ğŸ§¹ ì „ì²´ ì´ˆê¸°í™”: {total_sessions}ê°œ ì„¸ì…˜, {total_messages}ê°œ ë©”ì‹œì§€ ì‚­ì œ")

            return {
                "status": "All sessions reset successfully",
                "session_id": new_session_id,
                "cleared_sessions": total_sessions,
                "cleared_messages": total_messages
            }
            
    except Exception as e:
        print(f"âŒ ë¦¬ì…‹ ì˜¤ë¥˜: {e}")
        # ì˜¤ë¥˜ ë°œìƒì‹œì—ë„ ìƒˆ ì„¸ì…˜ ID ë°˜í™˜
        new_session_id = generate_session_id()
        
        return {
            "status": "Sessions reset due to error",
            "session_id": new_session_id,
            "error": str(e)
        }

# ğŸ”§ ê°œì„  7: í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
@app.get("/health")
async def health_check():
    stats = thread_safe_store.get_stats()
    return {
        "status": "healthy",
        "timestamp": time.time(),
        "sessions": stats['total_sessions'],
        "messages": stats['total_messages']
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "main:app", 
        host="0.0.0.0", 
        port=8000, 
        reload=True,
        workers=1,  # ë‹¨ì¼ ì›Œì»¤ë¡œ ë©”ëª¨ë¦¬ ê³µìœ  ë¬¸ì œ ë°©ì§€
        timeout_keep_alive=30,
        limit_concurrency=100,  # ë™ì‹œ ì—°ê²° ì œí•œ
        limit_max_requests=1000  # ìµœëŒ€ ìš”ì²­ ìˆ˜ ì œí•œ
    )