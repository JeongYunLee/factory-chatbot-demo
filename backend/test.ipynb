{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d81cc61",
   "metadata": {},
   "source": [
    "# ver1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3c04fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid, os, io, sys, time\n",
    "import asyncio\n",
    "import threading\n",
    "from contextlib import asynccontextmanager\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict\n",
    "from typing import Annotated\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import wraps\n",
    "\n",
    "from openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "# import chromadb\n",
    "# from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.errors import GraphRecursionError\n",
    "\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.output_parsers.openai_tools import JsonOutputToolsParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableConfig  \n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory, StreamlitChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langgraph.graph.message import add_messages\n",
    "from operator import itemgetter\n",
    "\n",
    "from langchain.agents import tool\n",
    "from langchain.agents import create_tool_calling_agent\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# from langchain_teddynote import logging\n",
    "from langsmith import traceable\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a511cc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv(override=True)\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in environment variables\")\n",
    "\n",
    "# ëª¨ë¸\n",
    "model = ChatOpenAI(\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    model=\"gpt-5.1-2025-11-13\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "251de744",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    question: str # ì§ˆë¬¸\n",
    "    q_type: str  # ì§ˆë¬¸ì˜ ìœ í˜•\n",
    "    answer: str | list[str]   # llmì´ ìƒì„±í•œ ë‹µë³€\n",
    "    session_id: str  # ì„¸ì…˜ ID ì¶”ê°€\n",
    "\n",
    "# ğŸ”§ ê°œì„  1: ìŠ¤ë ˆë“œ ì•ˆì „í•œ ì €ì¥ì†Œ\n",
    "import threading\n",
    "from collections import defaultdict\n",
    "\n",
    "class ThreadSafeStore:\n",
    "    def __init__(self):\n",
    "        self._store = {}\n",
    "        self._lock = threading.RLock()  # ì¬ì§„ì… ê°€ëŠ¥í•œ ë½\n",
    "    \n",
    "    def get_session_history(self, session_id: str):\n",
    "        with self._lock:\n",
    "            if session_id not in self._store:\n",
    "                self._store[session_id] = ChatMessageHistory()\n",
    "                print(f\"ğŸ†• ìƒˆë¡œìš´ ì„¸ì…˜ íˆìŠ¤í† ë¦¬ ìƒì„±: {session_id[:8]}...\")\n",
    "            return self._store[session_id]\n",
    "    \n",
    "    def clear_session(self, session_id: str = None):\n",
    "        with self._lock:\n",
    "            if session_id:\n",
    "                if session_id in self._store:\n",
    "                    message_count = len(self._store[session_id].messages)\n",
    "                    del self._store[session_id]\n",
    "                    return message_count\n",
    "                return 0\n",
    "            else:\n",
    "                total_sessions = len(self._store)\n",
    "                total_messages = sum(len(history.messages) for history in self._store.values())\n",
    "                self._store.clear()\n",
    "                return total_sessions, total_messages\n",
    "    \n",
    "    def get_stats(self):\n",
    "        with self._lock:\n",
    "            return {\n",
    "                'total_sessions': len(self._store),\n",
    "                'total_messages': sum(len(history.messages) for history in self._store.values())\n",
    "            }\n",
    "\n",
    "# ì „ì—­ ìŠ¤ë ˆë“œ ì•ˆì „ ì €ì¥ì†Œ\n",
    "thread_safe_store = ThreadSafeStore()\n",
    "\n",
    "# ì„¸ì…˜ IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\n",
    "def get_session_history(session_ids):\n",
    "    return thread_safe_store.get_session_history(session_ids)\n",
    "\n",
    "# ìƒˆë¡œìš´ ì„¸ì…˜ ID ìƒì„± í•¨ìˆ˜\n",
    "def generate_session_id():\n",
    "    return str(uuid.uuid4())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4651760a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "############################ nodes: Router ############################\n",
    "#######################################################################\n",
    "\n",
    "class Router(BaseModel):\n",
    "    type: str = Field(description=\"type of the query that model choose. Choose from ['general', 'domain_specific']\")\n",
    "\n",
    "router_output_parser = JsonOutputParser(pydantic_object=Router)\n",
    "router_format_instructions = router_output_parser.get_format_instructions()\n",
    "\n",
    "router_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "            You are an expert who classifies the type of question. There are two query types: ['general', 'domain_specific']\n",
    "\n",
    "            [general]\n",
    "            Questions unrelated to data query, such as translating English to Korean, asking for general knowledge (e.g., \"What is the capital of South Korea?\"), or queries that can be answered through a web search.\n",
    "\n",
    "            [domain_specific]\n",
    "            Questions related to 'factory' domain and data query, such as 'count the unique values of factories in Seoul', or count 'the number of rows in a table'.\n",
    "\n",
    "            <Output format>: Always respond with either \"general\" or \"domain_specific\" and nothing else. {format_instructions}\n",
    "            <chat_history>: {chat_history}\n",
    "            \n",
    "            <Question>: {query} \n",
    "            \"\"\",\n",
    "    input_variables=[\"query\", \"chat_history\"],\n",
    "    partial_variables={\"format_instructions\": router_format_instructions},\n",
    ")\n",
    "\n",
    "def router(state: GraphState) -> GraphState:\n",
    "    chain = router_prompt | model | router_output_parser\n",
    "    \n",
    "    router_with_history  = RunnableWithMessageHistory(\n",
    "        chain,\n",
    "        get_session_history,\n",
    "        input_messages_key=\"query\",\n",
    "        history_messages_key=\"chat_history\",\n",
    "    )\n",
    "    \n",
    "    router_result = router_with_history.invoke(\n",
    "        {\"query\": state[\"question\"]}, \n",
    "        {'configurable': {'session_id': state[\"session_id\"]}}\n",
    "    )\n",
    "    state[\"q_type\"] = router_result['type']\n",
    "    return state\n",
    "\n",
    "def router_conditional_edge(state: GraphState) -> GraphState:\n",
    "    q_type = state[\"q_type\"].strip()\n",
    "    return q_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "509f9de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ \n",
    "# def router(input):\n",
    "#     chain = router_prompt | model | router_output_parser\n",
    "    \n",
    "#     router_with_history  = RunnableWithMessageHistory(\n",
    "#         chain,\n",
    "#         get_session_history,\n",
    "#         input_messages_key=\"query\",\n",
    "#         history_messages_key=\"chat_history\",\n",
    "#     )\n",
    "    \n",
    "#     router_result = router_with_history.invoke(\n",
    "#         {\"query\": input}, \n",
    "#         {'configurable': {'session_id': '111'}}\n",
    "#     )\n",
    "#     return router_result\n",
    "\n",
    "# router('ì„œìš¸ì— êµ¬ë³„ë¡œ ëª‡ê°œì˜ ê³µì¥ì´ ìˆë‚˜ìš”?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b695e771",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "###################### nodes: Generate Python Pandas Code ########################\n",
    "##################################################################################\n",
    "\n",
    "class CodeGenerator(BaseModel):\n",
    "    code: str = Field(description=\"Python Pandas Code\")\n",
    "\n",
    "code_generator_output_parser = JsonOutputParser(pydantic_object=CodeGenerator)\n",
    "code_generator_format_instructions = code_generator_output_parser.get_format_instructions()\n",
    "\n",
    "code_generator_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "            You are an expert who can generate Python Pandas Code to answer the query.\n",
    "\n",
    "            Write the code with the following dataset metadata. Do not use any other columns except the ones provided in the metadata. The columns are written in Korean.\n",
    "\n",
    "            <Dataset Metadata>: \n",
    "            # Basic Information\n",
    "            1. 'ê³µì¥ê´€ë¦¬ë²ˆí˜¸' (Factory Management Number): Unique factory identification number. [Important] A single factory management number can appear across multiple rows. When counting the number of factories, always use unique/distinct values of this field.\n",
    "\n",
    "            # Company & Factory Information\n",
    "            2. 'íšŒì‚¬ëª…' (Company Name): Name of the company operating the factory. It's not unique. \n",
    "            3. 'ê³µì¥êµ¬ë¶„' (Factory Classification): Type/classification of the factory\n",
    "            4. 'ë‹¨ì§€ëª…' (Complex Name): Name of the industrial complex (if applicable)\n",
    "            5. 'ì„¤ë¦½êµ¬ë¶„' (Establishment Type): Classification of how the factory was established\n",
    "            6. 'ì…ì£¼í˜•íƒœ' (Occupancy Type): Type of occupancy arrangement\n",
    "            7. 'ë“±ë¡êµ¬ë¶„' (Registration Type): Classification of factory registration\n",
    "            8. 'ì „í™”ë²ˆí˜¸' (Phone Number): Contact phone number\n",
    "\n",
    "            # Employee Statistics\n",
    "            9. 'ë‚¨ìì¢…ì—…ì›' (Male Employees): Number of male employees\n",
    "            10. 'ì—¬ìì¢…ì—…ì›' (Female Employees): Number of female employees\n",
    "            11. 'ì™¸êµ­ì¸ë‚¨ìì¢…ì—…ì›' (Foreign Male Employees): Number of foreign male employees\n",
    "            12. 'ì™¸êµ­ì¸ì—¬ìì¢…ì—…ì›' (Foreign Female Employees): Number of foreign female employees\n",
    "            13. 'ì¢…ì—…ì›í•©ê³„' (Total Employees): Total number of employees\n",
    "\n",
    "            # Production Information\n",
    "            14. 'ìƒì‚°í’ˆ' (Products): Products manufactured at the factory\n",
    "            15. 'ì›ìì¬' (Raw Materials): Raw materials used in production\n",
    "            16. 'ê³µì¥ê·œëª¨' (Factory Scale): Size classification of the factory\n",
    "            \n",
    "            # Facility Specifications\n",
    "            17. 'ìš©ì§€ë©´ì ' (Land Area): Total land area in square meters\n",
    "            18. 'ì œì¡°ì‹œì„¤ë©´ì ' (Manufacturing Facility Area): Area dedicated to manufacturing facilities\n",
    "            19. 'ë¶€ëŒ€ì‹œì„¤ë©´ì ' (Auxiliary Facility Area): Area of auxiliary/support facilities\n",
    "            20. 'ê±´ì¶•ë©´ì ' (Building Area): Total building area\n",
    "            21. 'ì§€ì‹ì‚°ì—…ì„¼í„°ëª…' (Knowledge Industry Center Name): Name of knowledge industry center (if applicable)\n",
    "\n",
    "            # Location & Administrative\n",
    "            22. 'í•„ì§€ìˆ˜' (Number of Parcels): Number of land parcels\n",
    "            23. 'ê³µì¥ê´€ë¦¬ë²ˆí˜¸' (Factory Management Number): Unique factory identification number\n",
    "\n",
    "            #Standardized Fields (ì •ì œ_)\n",
    "            24. 'ì •ì œ_ê´€ë¦¬ê¸°ê´€' (Standardized Management Agency): Standardized name of the management agency \n",
    "            25. 'ì •ì œ_ë³´ìœ êµ¬ë¶„' (Standardized Ownership Type): Standardized ownership classification\n",
    "            26. 'ì •ì œ_ì‹œêµ°êµ¬ëª…' (Standardized District Name): Standardized city/county/district name\n",
    "            27. 'ì •ì œ_ì‹œë„ëª…' (Standardized Province Name): Standardized province/metropolitan city name\n",
    "            28. 'ì •ì œ_ì—…ì¢…ëª…' (Standardized Industry Name): Standardized industry name. It's not unique, so you need to calculate with 'ì •ì œ_ëŒ€í‘œì—…ì¢…' and show in 'ì •ì œ_ì—…ì¢…ëª…'\n",
    "            29. 'ì •ì œ_ëŒ€í‘œì—…ì¢…' (Standardized Primary Industry): Standardized primary industry classification. It's in code, so after use it, you need to show the name using 'ì •ì œ_ëŒ€í‘œì—…ì¢…'\n",
    "            29. 'ì •ì œ_ìš©ë„ì§€ì—­' (Standardized Zoning District): Standardized zoning/land use district\n",
    "            30. 'ì •ì œ_ì§€ëª©' (Standardized Land Category): Standardized land category classification\n",
    "\n",
    "            # Date Fields\n",
    "            31. 'ì •ì œ_ìµœì´ˆë“±ë¡ì¼' (Standardized Initial Registration Date): Standardized date of initial registration (format: YYYY-MM-DD)\n",
    "            32. 'ì •ì œ_ìµœì´ˆìŠ¹ì¸ì¼' (Standardized Initial Approval Date): Standardized date of initial approval (format: YYYY-MM-DD)\n",
    "\n",
    "            Write the code with the most efficient way.\n",
    "            <Output format>: Always respond with Python Pandas code. Always assign the final result to a variable called `return_var`. Do not use print(). {format_instructions}\n",
    "            <chat_history>: {chat_history}\n",
    "            \n",
    "            <Question>: {query} \n",
    "            \"\"\",\n",
    "    input_variables=[\"query\", \"chat_history\"],\n",
    "    partial_variables={\"format_instructions\": code_generator_format_instructions},\n",
    ")\n",
    "\n",
    "# def query_generator(state: GraphState) -> GraphState:\n",
    "#     chain = query_generator_prompt | model | query_generator_output_parser\n",
    "    \n",
    "#     query_generator_with_history  = RunnableWithMessageHistory(\n",
    "#         chain,\n",
    "#         get_session_history,\n",
    "#         input_messages_key=\"query\",\n",
    "#         history_messages_key=\"chat_history\",\n",
    "#     )\n",
    "    \n",
    "#     query_generator_result = query_generator_with_history.invoke(\n",
    "#         {\"query\": state[\"question\"]}, \n",
    "        \n",
    "#         {'configurable': {'session_id': state[\"session_id\"]}}\n",
    "#     )\n",
    "#     state[\"code\"] = query_generator_result['code']\n",
    "#     return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82485f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def code_generator(input):\n",
    "    '''\n",
    "    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ CSVì—ì„œ ì¿¼ë¦¬í•  ìˆ˜ ìˆëŠ” Python Pandas ì½”ë“œë¥¼ ì‘ì„±í•˜ëŠ” ë„êµ¬\n",
    "    '''\n",
    "    chain = code_generator_prompt | model | code_generator_output_parser\n",
    "    \n",
    "    code_generator_with_history  = RunnableWithMessageHistory(\n",
    "        chain,\n",
    "        get_session_history,\n",
    "        input_messages_key=\"query\",\n",
    "        history_messages_key=\"chat_history\",\n",
    "    )\n",
    "    \n",
    "    code_generator_result = code_generator_with_history.invoke(\n",
    "        {\"query\": input}, \n",
    "        {'configurable': {'session_id': '111'}}\n",
    "    )\n",
    "    return code_generator_result['code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be2ed564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeongyunl/Documents/GitHub/factory-chatbot-demo/env/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ†• ìƒˆë¡œìš´ ì„¸ì…˜ íˆìŠ¤í† ë¦¬ ìƒì„±: 111...\n",
      "import pandas as pd\n",
      "\n",
      "# ì—¬ì„± ì§ì› ë¹„ìœ¨ ê³„ì‚° (ì—¬ìì¢…ì—…ì› / ì¢…ì—…ì›í•©ê³„)\n",
      "# 0 ë˜ëŠ” NaNìœ¼ë¡œ ì¸í•œ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ì¡°ê±´ë¶€ ê³„ì‚°\n",
      "valid_emp = df['ì¢…ì—…ì›í•©ê³„'] > 0\n",
      "female_ratio = pd.Series(0, index=df.index, dtype='float64')\n",
      "female_ratio[valid_emp] = df.loc[valid_emp, 'ì—¬ìì¢…ì—…ì›'] / df.loc[valid_emp, 'ì¢…ì—…ì›í•©ê³„']\n",
      "\n",
      "# ì—¬ì„± ì§ì› ë¹„ìœ¨ì´ ë†’ì€ ê³µì¥ ì •ì˜: ìƒìœ„ 25% (ì‚¬ë¶„ìœ„ìˆ˜ ê¸°ì¤€)\n",
      "threshold = female_ratio.quantile(0.75)\n",
      "\n",
      "# ì—¬ì„± ë¹„ìœ¨ì´ ë†’ì€ ê³µì¥ë§Œ í•„í„°ë§\n",
      "high_female_df = df[female_ratio >= threshold].copy()\n",
      "\n",
      "# ê³µì¥ ë‹¨ìœ„ë¡œ ì¤‘ë³µ ì œê±° (ê³µì¥ê´€ë¦¬ë²ˆí˜¸ ê¸°ì¤€)\n",
      "# ë™ì¼ ê³µì¥ì´ ì—¬ëŸ¬ í–‰ì— ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ëŒ€í‘œ í–‰ 1ê°œë§Œ ì‚¬ìš©\n",
      "high_female_unique = high_female_df.drop_duplicates(subset=['ê³µì¥ê´€ë¦¬ë²ˆí˜¸'])\n",
      "\n",
      "# ì—…ì¢…ë³„(ì •ì œ_ëŒ€í‘œì—…ì¢… ì½”ë“œ ê¸°ì¤€) ê³µì¥ ìˆ˜ ì§‘ê³„\n",
      "industry_counts = (\n",
      "    high_female_unique\n",
      "    .groupby('ì •ì œ_ëŒ€í‘œì—…ì¢…')['ê³µì¥ê´€ë¦¬ë²ˆí˜¸']\n",
      "    .nunique()\n",
      "    .reset_index(name='ì—¬ì„±ë¹„ìœ¨_ë†’ì€_ê³µì¥ìˆ˜')\n",
      ")\n",
      "\n",
      "# ê³µì¥ ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬\n",
      "industry_counts = industry_counts.sort_values('ì—¬ì„±ë¹„ìœ¨_ë†’ì€_ê³µì¥ìˆ˜', ascending=False)\n",
      "\n",
      "# ì—…ì¢…ëª…(ì •ì œ_ì—…ì¢…ëª…)ì„ í•¨ê»˜ ë³´ê¸° ìœ„í•´ ëŒ€í‘œì—…ì¢… ì½”ë“œ ê¸°ì¤€ìœ¼ë¡œ ë§¤í•‘\n",
      "# ê° ëŒ€í‘œì—…ì¢… ì½”ë“œë‹¹ í•˜ë‚˜ì˜ ì—…ì¢…ëª…ì„ ëŒ€í‘œë¡œ ì‚¬ìš©\n",
      "industry_name_map = (\n",
      "    df.dropna(subset=['ì •ì œ_ëŒ€í‘œì—…ì¢…'])\n",
      "      .drop_duplicates(subset=['ì •ì œ_ëŒ€í‘œì—…ì¢…'])\n",
      "      .set_index('ì •ì œ_ëŒ€í‘œì—…ì¢…')['ì •ì œ_ì—…ì¢…ëª…']\n",
      ")\n",
      "\n",
      "industry_counts['ì •ì œ_ì—…ì¢…ëª…'] = industry_counts['ì •ì œ_ëŒ€í‘œì—…ì¢…'].map(industry_name_map)\n",
      "\n",
      "# ìµœì¢… ê²°ê³¼ë¥¼ return_varì— ì €ì¥\n",
      "return_var = industry_counts\n"
     ]
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "answer = code_generator(' ì—¬ì„± ì§ì› ë¹„ìœ¨ì´ ë†’ì€ ê³µì¥ì€ ì–´ë–¤ ì—…ì¢…ì´ ë§ì•„?')\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bed0ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def code_executor(input_code: str):\n",
    "    \"\"\"\n",
    "    LLMì´ ìƒì„±í•œ Pandas ì½”ë“œë¥¼ ì‹¤í–‰í•˜ê³  return_var ê°’ì„ ë°˜í™˜í•˜ëŠ” Tool.\n",
    "    dfëŠ” Tool ì•ˆì—ì„œ ì´ë¯¸ ê¸€ë¡œë²Œë¡œ ì„¤ì •ë˜ì–´ ìˆì–´ì•¼ í•¨.\n",
    "    \"\"\"\n",
    "    global df  # ì´ë¯¸ ì •ì˜ëœ dfë¥¼ ì‚¬ìš©\n",
    "    local_vars = {'df': df}\n",
    "    exec(input_code, local_vars)\n",
    "    if 'return_var' not in local_vars:\n",
    "        raise ValueError(\"Generated code did not assign value to 'return_var'.\")\n",
    "    return local_vars['return_var']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20c9b2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3k/09hbppyx33z8tmqmvw42bgqm0000gn/T/ipykernel_21420/2686250579.py:2: DtypeWarning: Columns (11,13,46) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('data/cleaned_ì „êµ­ê³µì¥ë“±ë¡í˜„í™©_preprocessed_seoul.csv')\n"
     ]
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "df = pd.read_csv('data/cleaned_ì „êµ­ê³µì¥ë“±ë¡í˜„í™©_preprocessed_seoul.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc07f09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "answer = code_generator(' ì—¬ì„± ì§ì› ë¹„ìœ¨ì´ ë†’ì€ ê³µì¥ì€ ì–´ë–¤ ì—…ì¢…ì´ ë§ì•„?')\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e1f5829",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def code_executor(input_code: str, max_retries=3):\n",
    "    \"\"\"\n",
    "    LLMì´ ìƒì„±í•œ Pandas ì½”ë“œë¥¼ ì•ˆì „í•˜ê²Œ ì‹¤í–‰í•˜ê³  return_var ë°˜í™˜.\n",
    "    dfëŠ” ê¸€ë¡œë²Œ ë³€ìˆ˜ ì‚¬ìš©.\n",
    "    NA, None, 0 ë“±ì˜ ì—ëŸ¬ ëŒ€ë¹„.\n",
    "    \"\"\"\n",
    "    global df\n",
    "    local_vars = {'df': df}\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            exec(input_code, local_vars)\n",
    "            if 'return_var' not in local_vars:\n",
    "                raise ValueError(\"Generated code did not assign value to 'return_var'.\")\n",
    "            return local_vars['return_var']\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ ì½”ë“œ ì‹¤í–‰ ì‹¤íŒ¨ (ì‹œë„ {attempt+1}/{max_retries}): {e}\")\n",
    "            # NAë‚˜ boolean ë¹„êµ ì—ëŸ¬ ë“± ì¬ì‹œë„ ê°€ëŠ¥\n",
    "            if attempt == max_retries - 1:\n",
    "                raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853e09f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "df = pd.read_csv('data/cleaned_ì „êµ­ê³µì¥ë“±ë¡í˜„í™©_preprocessed_seoul.csv')\n",
    "result = code_executor(answer)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b410e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ tools & Agents ############################\n",
    "\n",
    "# ğŸ”§ ê°œì„  3: OpenAI API ë ˆì´íŠ¸ ë¦¬ë¯¸íŒ… ë° ì¬ì‹œë„\n",
    "import openai\n",
    "from openai import RateLimitError, APITimeoutError\n",
    "\n",
    "def retry_on_failure(max_retries=3, delay=1):\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            last_exception = None\n",
    "            for attempt in range(max_retries):\n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "                except Exception as e:\n",
    "                    last_exception = e\n",
    "                    if attempt < max_retries - 1:\n",
    "                        print(f\"âš ï¸ ì‹œë„ {attempt + 1} ì‹¤íŒ¨, {delay}ì´ˆ í›„ ì¬ì‹œë„: {str(e)[:100]}\")\n",
    "                        time.sleep(delay * (attempt + 1))  # ì§€ìˆ˜ ë°±ì˜¤í”„\n",
    "                    else:\n",
    "                        print(f\"âŒ ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨: {str(e)}\")\n",
    "            raise last_exception\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "@retry_on_failure(max_retries=3, delay=2)\n",
    "def call_openai_with_retry(client, **kwargs):\n",
    "    try:\n",
    "        return client.chat.completions.create(**kwargs)\n",
    "    except RateLimitError as e:\n",
    "        print(f\"âš ï¸ OpenAI ë ˆì´íŠ¸ ë¦¬ë¯¸íŠ¸: {e}\")\n",
    "        time.sleep(5)  # ë ˆì´íŠ¸ ë¦¬ë¯¸íŠ¸ ì‹œ ë” ì˜¤ë˜ ëŒ€ê¸°\n",
    "        raise\n",
    "    except APITimeoutError as e:\n",
    "        print(f\"âš ï¸ OpenAI íƒ€ì„ì•„ì›ƒ: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ OpenAI API ì˜¤ë¥˜: {e}\")\n",
    "        raise\n",
    "    \n",
    "tools = [code_generator, code_executor]\n",
    "\n",
    "agent_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that answers ONLY in Korean. \"\n",
    "            \"You must follow these rules:\\n\"\n",
    "            \"1. If the question's type (`q_type`) is 'domain_specific', you MUST use tools (`code_generator` and `code_executor`) to generate Python Pandas code and execute it step by step. \"\n",
    "            \"   Always base your answer on the return_var from code execution. If the data does not allow you to answer, respond with 'ì°¸ì¡°í•  ì •ë³´ê°€ ì—†ì–´ì„œ ë‹µë³€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'\\n\"\n",
    "            \"2. If the question's type is NOT 'domain_specific', do NOT use any tools. You may answer directly, but you MUST begin your answer with 'ë°ì´í„°ì— ê¸°ë°˜í•˜ì§€ ì•Šì€ ë‹µë³€ì…ë‹ˆë‹¤' (This answer is not based on data).\\n\"\n",
    "            \"3. You may repeat code generation and execution multiple times if needed, but you must always base your answer on return_var when using tools. \"\n",
    "            \"Always answer in Korean, never in English.\"\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"human\", \"{retrieved_data}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def agent(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Agent ì‹¤í–‰ í•¨ìˆ˜\n",
    "    - domain_specific ì§ˆë¬¸ì€ tools(code_generator + safe_code_executor) ì‚¬ìš©\n",
    "    - code ì‹¤í–‰ ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ êµ¬ì¡° ì ìš©\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Agent ìƒì„±\n",
    "        agent_obj = create_tool_calling_agent(model, tools, agent_prompt)\n",
    "\n",
    "        agent_executor = AgentExecutor(\n",
    "            agent=agent_obj,\n",
    "            tools=tools,\n",
    "            verbose=False,\n",
    "            max_iterations=10,\n",
    "            max_execution_time=120,\n",
    "            handle_parsing_errors=True,\n",
    "            return_intermediate_steps=True\n",
    "        )\n",
    "\n",
    "        agent_with_history = RunnableWithMessageHistory(\n",
    "            agent_executor,\n",
    "            get_session_history,\n",
    "            history_messages_key=\"chat_history\",\n",
    "        )\n",
    "\n",
    "        max_attempts = 3\n",
    "        for attempt in range(max_attempts):\n",
    "            try:\n",
    "                # Agent ì‹¤í–‰\n",
    "                result = agent_with_history.invoke(\n",
    "                    {\"input\": state[\"question\"], \n",
    "                     \"retrieved_data\": state.get(\"context\"), \n",
    "                     \"relevance\": state.get(\"relevance\")},\n",
    "                    {'configurable': {'session_id': state[\"session_id\"]}}\n",
    "                )\n",
    "\n",
    "                # ê²°ê³¼ì—ì„œ ì½”ë“œ ì‹¤í–‰ì´ í•„ìš”í•˜ë©´ safe_code_executor ì‚¬ìš©\n",
    "                # tools ë‚´ë¶€ì—ì„œ ìë™ í˜¸ì¶œë¨\n",
    "                state['answer'] = result['output']\n",
    "                return state\n",
    "\n",
    "            except Exception as e_inner:\n",
    "                print(f\"âš ï¸ ì—ì´ì „íŠ¸ ì‹œë„ {attempt+1}/{max_attempts} ì‹¤íŒ¨: {e_inner}\")\n",
    "                if attempt == max_attempts - 1:\n",
    "                    raise\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì—ì´ì „íŠ¸ ì‹¤í–‰ ìµœì¢… ì‹¤íŒ¨: {e}\")\n",
    "        state['answer'] = f\"ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)[:100]}\"\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bf337ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "############################ Workflow Graph ############################\n",
    "########################################################################\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "workflow.add_node(\"Router\", router)\n",
    "workflow.add_node(\"Agent\", agent)\n",
    "\n",
    "workflow.add_edge(\"Router\", \"Agent\")\n",
    "workflow.add_edge(\"Agent\", END)\n",
    "\n",
    "workflow.set_entry_point(\"Router\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8947e5e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013eb07a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e49f2761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ†• ìƒˆë¡œìš´ ì„¸ì…˜ íˆìŠ¤í† ë¦¬ ìƒì„±: aaa...\n",
      "ğŸ†• ìƒˆë¡œìš´ ì„¸ì…˜ íˆìŠ¤í† ë¦¬ ìƒì„±: 111...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'ì™¸êµ­ì¸ ê·¼ë¡œìê°€ ë§ì€ ê³µì¥ì€ ì–´ë””ì•¼? ì—…ì¢… íŠ¹ì§•ë„ ì•Œë ¤ì¤˜',\n",
       " 'q_type': 'domain_specific',\n",
       " 'answer': 'ë‹¤ìŒ ë‚´ìš©ì€ ì œê³µëœ ê³µì¥ ë°ì´í„°(ì„œìš¸ ì†Œì¬)ë¥¼ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤.\\n\\n1. **ì™¸êµ­ì¸ ê·¼ë¡œìê°€ ë§ì€ ê³µì¥ TOP 10 (ì¸ì› ê¸°ì¤€)**  \\n   - (1) **(ì£¼)ì§€êµ¬í™”í•™**  \\n     - ê³µì¥ê´€ë¦¬ë²ˆí˜¸: 260210101881100  \\n     - ìœ„ì¹˜: ì„œìš¸íŠ¹ë³„ì‹œ ì„±ë™êµ¬  \\n     - ì—…ì¢…: ì‚¬ë¬´ ë° íšŒí™”ìš©í’ˆ ì œì¡°ì—…  \\n     - ì¢…ì—…ì›í•©ê³„: 426ëª…  \\n     - ì™¸êµ­ì¸ ê·¼ë¡œì: 213ëª… (ë¹„ìœ¨ ì•½ **50%**)  \\n\\n   - (2) **(ì£¼)ì˜ì¼í”„ë ˆì‹œì ¼**  \\n     - ê³µì¥ê´€ë¦¬ë²ˆí˜¸: 115452019436985  \\n     - ìœ„ì¹˜: ì„œìš¸íŠ¹ë³„ì‹œ ê¸ˆì²œêµ¬  \\n     - ì—…ì¢…: ê·¸ ì™¸ ê¸°íƒ€ ì „ìë¶€í’ˆ ì œì¡°ì—…  \\n     - ì¢…ì—…ì›í•©ê³„: 501ëª…  \\n     - ì™¸êµ­ì¸ ê·¼ë¡œì: 84ëª… (ë¹„ìœ¨ ì•½ **16.8%**)  \\n\\n   - (3) **(ì£¼)í•„ë¡œìŠ¤ì£¼ì–¼ë¦¬**  \\n     - ê³µì¥ê´€ë¦¬ë²ˆí˜¸: 111102001023720  \\n     - ìœ„ì¹˜: ì„œìš¸íŠ¹ë³„ì‹œ ì¢…ë¡œêµ¬  \\n     - ì—…ì¢…: ê·€ê¸ˆì† ë° ê´€ë ¨ì œí’ˆ ì œì¡°ì—…  \\n     - ì¢…ì—…ì›í•©ê³„: 63ëª…  \\n     - ì™¸êµ­ì¸ ê·¼ë¡œì: 63ëª… (ë¹„ìœ¨ **100%**)  \\n\\n   - (4) **(ì£¼)ë¶€ë˜ë‹¹**  \\n     - ê³µì¥ê´€ë¦¬ë²ˆí˜¸: 110111051524101  \\n     - ìœ„ì¹˜: ì„œìš¸íŠ¹ë³„ì‹œ ì„±ë™êµ¬  \\n     - ì—…ì¢…: ì—¬ììš© ê²‰ì˜· ì œì¡°ì—…  \\n     - ì¢…ì—…ì›í•©ê³„: 1,092ëª…  \\n     - ì™¸êµ­ì¸ ê·¼ë¡œì: 36ëª… (ë¹„ìœ¨ ì•½ **3.3%**)  \\n\\n   - (5) **(ì£¼)ì œì´ì‹œìŠ¤ë©”ë””ì¹¼**  \\n     - ê³µì¥ê´€ë¦¬ë²ˆí˜¸: 115452004078321  \\n     - ìœ„ì¹˜: ì„œìš¸íŠ¹ë³„ì‹œ ê¸ˆì²œêµ¬  \\n     - ì—…ì¢…: ê·¸ ì™¸ ê¸°íƒ€ ì˜ë£Œìš© ê¸°ê¸° ì œì¡°ì—…  \\n     - ì¢…ì—…ì›í•©ê³„: 1,110ëª…  \\n     - ì™¸êµ­ì¸ ê·¼ë¡œì: 36ëª… (ë¹„ìœ¨ ì•½ **3.2%**)  \\n\\n   - (6) **ì‚¼ì§„ê³µì—…(ì£¼)**  \\n     - ê³µì¥ê´€ë¦¬ë²ˆí˜¸: 115302003050939  \\n     - ìœ„ì¹˜: ì„œìš¸íŠ¹ë³„ì‹œ êµ¬ë¡œêµ¬  \\n     - ì—…ì¢…: ì•¡ì²´ íŒí”„ ì œì¡°ì—…  \\n     - ì¢…ì—…ì›í•©ê³„: 68ëª…  \\n     - ì™¸êµ­ì¸ ê·¼ë¡œì: 34ëª… (ë¹„ìœ¨ ì•½ **50%**)  \\n\\n   - (7) **(ì£¼)ì–´ë‚˜ë”í•„**  \\n     - ê³µì¥ê´€ë¦¬ë²ˆí˜¸: 110111041442700  \\n     - ìœ„ì¹˜: ì„œìš¸íŠ¹ë³„ì‹œ ì„±ë™êµ¬  \\n     - ì—…ì¢…: ê·¸ ì™¸ ê¸°íƒ€ ë´‰ì œì˜ë³µ ì œì¡°ì—…  \\n     - ì¢…ì—…ì›í•©ê³„: 186ëª…  \\n     - ì™¸êµ­ì¸ ê·¼ë¡œì: 33ëª… (ë¹„ìœ¨ ì•½ **17.7%**)  \\n\\n   - (8) **ì‚¼ì–‘ëª¨í”¼(ì£¼)**  \\n     - ê³µì¥ê´€ë¦¬ë²ˆí˜¸: 115451998000005  \\n     - ìœ„ì¹˜: ì„œìš¸íŠ¹ë³„ì‹œ ê¸ˆì²œêµ¬  \\n     - ì—…ì¢…: ëª¨í”¼ì œí’ˆ ì œì¡°ì—…  \\n     - ì¢…ì—…ì›í•©ê³„: 225ëª…  \\n     - ì™¸êµ­ì¸ ê·¼ë¡œì: 33ëª… (ë¹„ìœ¨ ì•½ **14.7%**)  \\n\\n   - (9) **ì•„ì£¼ì–‘ë§(ì£¼)**  \\n     - ê³µì¥ê´€ë¦¬ë²ˆí˜¸: 110111099727500  \\n     - ìœ„ì¹˜: ì„œìš¸íŠ¹ë³„ì‹œ ì„±ë™êµ¬  \\n     - ì—…ì¢…: ìŠ¤íƒ€í‚¹ ë° ê¸°íƒ€ ì–‘ë§ ì œì¡°ì—…  \\n     - ì¢…ì—…ì›í•©ê³„: 273ëª…  \\n     - ì™¸êµ­ì¸ ê·¼ë¡œì: 33ëª… (ë¹„ìœ¨ ì•½ **12.1%**)  \\n\\n   - (10) **(ì£¼)ì›ìš°ì´ì—”ì§€**  \\n     - ê³µì¥ê´€ë¦¬ë²ˆí˜¸: 115002017380280  \\n     - ìœ„ì¹˜: ì„œìš¸íŠ¹ë³„ì‹œ ê°•ì„œêµ¬  \\n     - ì—…ì¢…: ë°©ì†¡ì¥ë¹„ ì œì¡°ì—…  \\n     - ì¢…ì—…ì›í•©ê³„: 279ëª…  \\n     - ì™¸êµ­ì¸ ê·¼ë¡œì: 33ëª… (ë¹„ìœ¨ ì•½ **11.8%**)  \\n\\n2. **ì™¸êµ­ì¸ ê·¼ë¡œìê°€ ë§ì€ ê³µì¥ì˜ ì—…ì¢… ë¶„í¬(ìƒìœ„ 10ê°œ ê¸°ì¤€)**  \\n   ìƒìœ„ 10ê°œ ê³µì¥ì€ ëª¨ë‘ ì„œë¡œ ë‹¤ë¥¸ ì—…ì¢…ì— ì†í•´ ìˆì–´, ì—…ì¢…ë³„ë¡œ ê° 1ê°œ ê³µì¥(10%)ì”© ì°¨ì§€í•©ë‹ˆë‹¤.\\n\\n   í¬í•¨ëœ ì—…ì¢…ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.  \\n   - ì‚¬ë¬´ ë° íšŒí™”ìš©í’ˆ ì œì¡°ì—…  \\n   - ê·¸ ì™¸ ê¸°íƒ€ ì „ìë¶€í’ˆ ì œì¡°ì—…  \\n   - ê·€ê¸ˆì† ë° ê´€ë ¨ì œí’ˆ ì œì¡°ì—…  \\n   - ì—¬ììš© ê²‰ì˜· ì œì¡°ì—…  \\n   - ê·¸ ì™¸ ê¸°íƒ€ ì˜ë£Œìš© ê¸°ê¸° ì œì¡°ì—…  \\n   - ì•¡ì²´ íŒí”„ ì œì¡°ì—…  \\n   - ê·¸ ì™¸ ê¸°íƒ€ ë´‰ì œì˜ë³µ ì œì¡°ì—…  \\n   - ëª¨í”¼ì œí’ˆ ì œì¡°ì—…  \\n   - ìŠ¤íƒ€í‚¹ ë° ê¸°íƒ€ ì–‘ë§ ì œì¡°ì—…  \\n   - ë°©ì†¡ì¥ë¹„ ì œì¡°ì—…  \\n\\n3. **ì—…ì¢…ë³„ íŠ¹ì§•(ë°ì´í„°ì—ì„œ ë³´ì´ëŠ” ê²½í–¥)**  \\n   - **ì˜ë¥˜Â·ë´‰ì œÂ·ëª¨í”¼Â·ì–‘ë§ ë“± ë…¸ë™ì§‘ì•½ì  ì—…ì¢…**  \\n     - ì—¬ììš© ê²‰ì˜·, ê¸°íƒ€ ë´‰ì œì˜ë³µ, ëª¨í”¼ì œí’ˆ, ìŠ¤íƒ€í‚¹Â·ì–‘ë§ ì œì¡°ì—… ë“±ì—ì„œ ì™¸êµ­ì¸ ê·¼ë¡œì ìˆ˜ê°€ ìƒëŒ€ì ìœ¼ë¡œ ë§ìŒ.  \\n     - ë°˜ë³µÂ·ìˆ™ë ¨ ë…¸ë™ì´ í•„ìš”í•œ ê³µì •ì´ ë§ì•„ ì™¸êµ­ì¸ ì¸ë ¥ì„ í™œìš©í•˜ëŠ” ë¹„ì¤‘ì´ ë†’ì€ ê²ƒìœ¼ë¡œ í•´ì„ ê°€ëŠ¥.  \\n\\n   - **ê·€ê¸ˆì†Â·ì£¼ì–¼ë¦¬ ì—…ì¢…**  \\n     - (ì£¼)í•„ë¡œìŠ¤ì£¼ì–¼ë¦¬ëŠ” ì¢…ì—…ì› ì „ì›ì´ ì™¸êµ­ì¸ìœ¼ë¡œ ì§‘ê³„ë˜ì–´, íŠ¹ì • ê¸°ìˆ Â·ê³µì •ì— ì™¸êµ­ì¸ ìˆ™ë ¨ê³µì„ ì§‘ì¤‘ì ìœ¼ë¡œ ì“°ëŠ” ì‚¬ë¡€ë¡œ ë³´ì„.  \\n\\n   - **ê¸°ê³„Â·ì „ìÂ·ì˜ë£Œê¸°ê¸°Â·ë°©ì†¡ì¥ë¹„ ë“± ì œì¡°ì—…**  \\n     - ì „ìë¶€í’ˆ, ì˜ë£Œê¸°ê¸°, ì•¡ì²´ íŒí”„, ë°©ì†¡ì¥ë¹„ ì œì¡°ì—…ì—ì„œë„ ì™¸êµ­ì¸ ê·¼ë¡œìê°€ ìƒë‹¹ìˆ˜ í¬í•¨.  \\n     - ìƒì‚°ë¼ì¸Â·ì¡°ë¦½Â·ê°€ê³µ ê³µì •ì— ì™¸êµ­ì¸ ê·¼ë¡œìê°€ íˆ¬ì…ë˜ëŠ” êµ¬ì¡°ë¡œ ì¶”ì • ê°€ëŠ¥.  \\n\\nì •ë¦¬í•˜ë©´, ì´ ë°ì´í„°ì—ì„œ **ì™¸êµ­ì¸ ê·¼ë¡œìê°€ ë§ì€ ê³µì¥**ì€ ì„œìš¸ì˜ ì„±ë™êµ¬Â·ê¸ˆì²œêµ¬Â·êµ¬ë¡œêµ¬Â·ê°•ì„œêµ¬Â·ì¢…ë¡œêµ¬ ë“±ì— ë¶„í¬í•˜ê³ , **ì˜ë¥˜Â·ë´‰ì œÂ·ëª¨í”¼Â·ì–‘ë§ ê°™ì€ ë…¸ë™ì§‘ì•½ ì—…ì¢…ê³¼ ì „ìÂ·ê¸°ê³„Â·ì˜ë£Œê¸°ê¸°Â·ë°©ì†¡ì¥ë¹„ ê°™ì€ ì œì¡°ì—… ì „ë°˜**ì—ì„œ ì™¸êµ­ì¸ ê·¼ë¡œì í™œìš© ë¹„ì¤‘ì´ ë†’ê²Œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.',\n",
       " 'session_id': 'aaa'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = RunnableConfig(recursion_limit=20, configurable={\"session_id\": \"1\", \"thread_id\": uuid.uuid4().hex})  \n",
    "\n",
    "question = (\n",
    "    \"ì™¸êµ­ì¸ ê·¼ë¡œìê°€ ë§ì€ ê³µì¥ì€ ì–´ë””ì•¼? ì—…ì¢… íŠ¹ì§•ë„ ì•Œë ¤ì¤˜\"\n",
    ")\n",
    "\n",
    "inputs = GraphState(\n",
    "    question=question,\n",
    "    session_id='aaa',\n",
    "    q_type='',\n",
    "    answer='',\n",
    ")\n",
    "\n",
    "answer = graph.invoke(inputs, config=config)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce4db82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3k/09hbppyx33z8tmqmvw42bgqm0000gn/T/ipykernel_76626/2030280934.py:1: DtypeWarning: Columns (11,13,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('data/cleaned_ì „êµ­ê³µì¥ë“±ë¡í˜„í™©_preprocessed_seoul.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/cleaned_ì „êµ­ê³µì¥ë“±ë¡í˜„í™©_preprocessed_seoul.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce1be15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['__row_uid__', 'ì‹œë„ëª…', 'ì‹œêµ°êµ¬ëª…', 'ê´€ë¦¬ê¸°ê´€', 'íšŒì‚¬ëª…', 'ê³µì¥êµ¬ë¶„', 'ë‹¨ì§€ëª…', 'ì„¤ë¦½êµ¬ë¶„',\n",
       "       'ì…ì£¼í˜•íƒœ', 'ë³´ìœ êµ¬ë¶„', 'ìµœì´ˆìŠ¹ì¸ì¼', 'ìµœì´ˆë“±ë¡ì¼', 'ë“±ë¡êµ¬ë¶„', 'ë“±ë¡ì¼', 'ì „í™”ë²ˆí˜¸', 'ë‚¨ìì¢…ì—…ì›',\n",
       "       'ì—¬ìì¢…ì—…ì›', 'ì™¸êµ­ì¸ë‚¨ìì¢…ì—…ì›', 'ì™¸êµ­ì¸ì—¬ìì¢…ì—…ì›', 'ì¢…ì—…ì›í•©ê³„', 'ìƒì‚°í’ˆ', 'ì›ìì¬', 'ê³µì¥ê·œëª¨', 'ìš©ë„ì§€ì—­',\n",
       "       'ì§€ëª©', 'ìš©ì§€ë©´ì ', 'ì œì¡°ì‹œì„¤ë©´ì ', 'ë¶€ëŒ€ì‹œì„¤ë©´ì ', 'ê±´ì¶•ë©´ì ', 'ì§€ì‹ì‚°ì—…ì„¼í„°ëª…', 'ëŒ€í‘œì—…ì¢…', 'ì—…ì¢…ëª…',\n",
       "       'ì—…ì¢…ì½”ë“œ', 'ì°¨ìˆ˜', 'ë²•ì¸ì£¼ì†Œ', 'í•„ì§€ìˆ˜', 'ê³µì¥ì£¼ì†Œ', 'ê³µì¥ì£¼ì†Œ_ì§€ë²ˆ', 'ê³µì¥ê´€ë¦¬ë²ˆí˜¸', 'ì •ì œ_ê´€ë¦¬ê¸°ê´€',\n",
       "       'ì½”ë“œë§¤í•‘_ê´€ë¦¬ê¸°ê´€', 'ëˆ„ì _ê´€ë¦¬ê¸°ê´€', 'ì •ì œ_ëŒ€í‘œì—…ì¢…', 'ì½”ë“œë§¤í•‘_ëŒ€í‘œì—…ì¢…', 'ëˆ„ì _ëŒ€í‘œì—…ì¢…', 'ì •ì œ_ë“±ë¡ì¼',\n",
       "       'ëˆ„ì _ë“±ë¡ì¼', 'ì •ì œ_ë³´ìœ êµ¬ë¶„', 'ì½”ë“œë§¤í•‘_ë³´ìœ êµ¬ë¶„', 'ëˆ„ì _ë³´ìœ êµ¬ë¶„', 'ì •ì œ_ì‹œêµ°êµ¬ëª…', 'ì½”ë“œë§¤í•‘_ì‹œêµ°êµ¬ëª…',\n",
       "       'ëˆ„ì _ì‹œêµ°êµ¬ëª…', 'ì •ì œ_ì‹œë„ëª…', 'ì½”ë“œë§¤í•‘_ì‹œë„ëª…', 'ëˆ„ì _ì‹œë„ëª…', 'ì •ì œ_ì—…ì¢…ëª…', 'ëˆ„ì _ì—…ì¢…ëª…',\n",
       "       'ì •ì œ_ì—…ì¢…ì½”ë“œ', 'ì½”ë“œë§¤í•‘_ì—…ì¢…ì½”ë“œ', 'ëˆ„ì _ì—…ì¢…ì½”ë“œ', 'ì •ì œ_ìš©ë„ì§€ì—­', 'ì½”ë“œë§¤í•‘_ìš©ë„ì§€ì—­', 'ëˆ„ì _ìš©ë„ì§€ì—­',\n",
       "       'ì •ì œ_ì§€ëª©', 'ì½”ë“œë§¤í•‘_ì§€ëª©', 'ëˆ„ì _ì§€ëª©', 'ì •ì œ_ìµœì´ˆë“±ë¡ì¼', 'ëˆ„ì _ìµœì´ˆë“±ë¡ì¼', 'ì •ì œ_ìµœì´ˆìŠ¹ì¸ì¼',\n",
       "       'ëˆ„ì _ìµœì´ˆìŠ¹ì¸ì¼'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7c5d12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì§ˆë¬¸í•˜ì‹  â€œì™¸êµ­ì¸ ê·¼ë¡œìê°€ ë§ì€ ê³µì¥â€ê³¼ â€œì—…ì¢… íŠ¹ì§•â€ì„, ì œê³µëœ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ì •ë¦¬í•´ ë“œë¦´ê²Œìš”.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. ì™¸êµ­ì¸ ê·¼ë¡œìê°€ ë§ì€ ê³µì¥ (ìƒìœ„ ì‚¬ë¡€)\n",
      "\n",
      "ì™¸êµ­ì¸ ë¹„ìœ¨(ì™¸êµ­ì¸ ìˆ˜ / ì „ì²´ ì¢…ì—…ì› ìˆ˜)ì´ ë†’ì€ ê³µì¥ ê¸°ì¤€ ìƒìœ„ ê³µì¥ë“¤ì…ë‹ˆë‹¤.\n",
      "\n",
      "### 1) ì™¸êµ­ì¸ ê·¼ë¡œì 100%ì¸ ê³µì¥ë“¤\n",
      "(ì „ì²´ ì¢…ì—…ì›ì´ ëª¨ë‘ ì™¸êµ­ì¸ì¸ ê²½ìš°)\n",
      "\n",
      "- (ì£¼)í•„ë¡œìŠ¤ì£¼ì–¼ë¦¬  \n",
      "  - ìœ„ì¹˜: ì„œìš¸íŠ¹ë³„ì‹œ ì¢…ë¡œêµ¬  \n",
      "  - ì—…ì¢…: ê·€ê¸ˆì† ë° ê´€ë ¨ì œí’ˆ ì œì¡°ì—… (ì½”ë“œ 33110)  \n",
      "  - ì¢…ì—…ì› 63ëª… ì „ì›ì´ ì™¸êµ­ì¸\n",
      "\n",
      "- ì‹ í¥íŠ¸ë˜í”½(ì£¼)  \n",
      "  - ìœ„ì¹˜: ì„œìš¸íŠ¹ë³„ì‹œ ì€í‰êµ¬  \n",
      "  - ì—…ì¢…: ì „ê¸°ê²½ë³´ ë° ì‹ í˜¸ì¥ì¹˜ ì œì¡°ì—… (ì½”ë“œ 28901)  \n",
      "  - ì¢…ì—…ì› 18ëª… ì „ì›ì´ ì™¸êµ­ì¸\n",
      "\n",
      "- (ì£¼)ìë°”ë„¤íŠ¸ì›ìŠ¤  \n",
      "  - ìœ„ì¹˜: ì„œìš¸íŠ¹ë³„ì‹œ ê¸ˆì²œêµ¬  \n",
      "  - ì—…ì¢…: ë°©ì†¡ì¥ë¹„ ì œì¡°ì—… (ì½”ë“œ 26421)  \n",
      "  - ì¢…ì—…ì› 18ëª… ì „ì›ì´ ì™¸êµ­ì¸\n",
      "\n",
      "- ì‹ ê´‘í”„ë¦°í…Œí¬  \n",
      "  - ìœ„ì¹˜: ì„œìš¸íŠ¹ë³„ì‹œ ì˜ë“±í¬êµ¬  \n",
      "  - ì—…ì¢…: ê¸°íƒ€ ì¸ì‡„ì—… (ì½”ë“œ 18119)  \n",
      "  - ì¢…ì—…ì› 12ëª… ì „ì›ì´ ì™¸êµ­ì¸\n",
      "\n",
      "- í‘¸ë¦„ì¼í…  \n",
      "  - ìœ„ì¹˜: ì„œìš¸íŠ¹ë³„ì‹œ ê¸ˆì²œêµ¬  \n",
      "  - ì—…ì¢…: ë¬¼ì§ˆ ê²€ì‚¬Â·ì¸¡ì •Â·ë¶„ì„ê¸°êµ¬ ì œì¡°ì—… (ì½”ë“œ 27213)  \n",
      "  - ì¢…ì—…ì› 3ëª… ì „ì›ì´ ì™¸êµ­ì¸  \n",
      "\n",
      "ì´ë“¤ ê³µì¥ì€ ê·œëª¨ëŠ” í¬ì§€ ì•Šì§€ë§Œ, íŠ¹ì • ê¸°ìˆ Â·ì œì¡° ê³µì •ì— ì™¸êµ­ì¸ ì¸ë ¥ì´ ì „ì ìœ¼ë¡œ íˆ¬ì…ëœ í˜•íƒœì…ë‹ˆë‹¤.\n",
      "\n",
      "### 2) ì™¸êµ­ì¸ ë¹„ìœ¨ì´ 50% ì´ìƒì¸ ì£¼ìš” ê³µì¥ë“¤\n",
      "\n",
      "- (ì£¼)ì •ì •ì—ì´ìŠ¤  \n",
      "  - ìœ„ì¹˜: ì„œìš¸íŠ¹ë³„ì‹œ ê¸ˆì²œêµ¬  \n",
      "  - ì—…ì¢…: ë„ì‹œë½ë¥˜ ì œì¡°ì—… (10701)  \n",
      "  - ì™¸êµ­ì¸ 12ëª… / ì „ì²´ 15ëª… (ë¹„ìœ¨ 80%)\n",
      "\n",
      "- (ì£¼)ì •í˜¸ ì–´í˜ëŸ´  \n",
      "  - ìœ„ì¹˜: ì„œìš¸íŠ¹ë³„ì‹œ ë™ëŒ€ë¬¸êµ¬  \n",
      "  - ì—…ì¢…: ë‚¨ììš© ê²‰ì˜· ì œì¡°ì—… (14111)  \n",
      "  - ì™¸êµ­ì¸ 24ëª… / ì „ì²´ 36ëª… (ë¹„ìœ¨ ì•½ 66.7%)\n",
      "\n",
      "- í•œì˜¬ì„¬ìœ   \n",
      "  - ìœ„ì¹˜: ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë¶êµ¬  \n",
      "  - ì—…ì¢…: ìŠ¤íƒ€í‚¹ ë° ê¸°íƒ€ ì–‘ë§ ì œì¡°ì—… (14411)  \n",
      "  - ì™¸êµ­ì¸ 6ëª… / ì „ì²´ 9ëª… (ë¹„ìœ¨ ì•½ 66.7%)\n",
      "\n",
      "- ì‹ ì²œì‹í’ˆ ì£¼ì‹íšŒì‚¬ ì§€ì  / ì‹ ì²œì‹í’ˆ(ì£¼)  \n",
      "  - ìœ„ì¹˜: ì„œìš¸íŠ¹ë³„ì‹œ ì„±ë™êµ¬  \n",
      "  - ì—…ì¢…: ë–¡ë¥˜ ì œì¡°ì—… (10601)  \n",
      "  - ì§€ì : ì™¸êµ­ì¸ 15 / 24ëª… (62.5%)  \n",
      "  - ë³¸ì‚¬: ì™¸êµ­ì¸ 18 / 36ëª… (50%)\n",
      "\n",
      "- (ì£¼)ì§€êµ¬í™”í•™  \n",
      "  - ìœ„ì¹˜: ì„œìš¸íŠ¹ë³„ì‹œ ì„±ë™êµ¬  \n",
      "  - ì—…ì¢…: ì‚¬ë¬´ ë° íšŒí™”ìš©í’ˆ ì œì¡°ì—… (33920)  \n",
      "  - ì™¸êµ­ì¸ 213ëª… / ì „ì²´ 426ëª… (ë¹„ìœ¨ 50%)  \n",
      "  - ì ˆëŒ€ì ì¸ ì™¸êµ­ì¸ ì¸ì› ìˆ˜ê°€ ê°€ì¥ ë§ì€ í¸(200ëª… ì´ìƒ)\n",
      "\n",
      "- ì‚¼ì§„ê³µì—…(ì£¼)  \n",
      "  - ìœ„ì¹˜: ì„œìš¸íŠ¹ë³„ì‹œ êµ¬ë¡œêµ¬  \n",
      "  - ì—…ì¢…: ì•¡ì²´ íŒí”„ ì œì¡°ì—… (29131)  \n",
      "  - ì™¸êµ­ì¸ 34ëª… / ì „ì²´ 68ëª… (50%)\n",
      "\n",
      "ì´ ì™¸ì—ë„ ì˜ë¥˜Â·ì„¬ìœ , í™”í•™, ì˜ë£Œê¸°ê¸°, ë¶„ì„ê¸°ê¸° ë“± ë‹¤ì–‘í•œ ì—…ì¢…ì—ì„œ ì™¸êµ­ì¸ ë¹„ìœ¨ì´ 50% ì•ˆíŒì¸ ê³µì¥ë“¤ì´ ë‹¤ìˆ˜ ì¡´ì¬í•©ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "## 2. ì™¸êµ­ì¸ ê·¼ë¡œìê°€ ë§ì€ ì—…ì¢… (ì—…ì¢…ë³„ íŠ¹ì§•)\n",
      "\n",
      "ì—…ì¢…ë³„ë¡œ ì™¸êµ­ì¸ ê·¼ë¡œì ë¹„ìœ¨ì´ ë†’ì€ ìƒìœ„ 10ê°œ ì—…ì¢…ì…ë‹ˆë‹¤.  \n",
      "(ì—¬ê¸°ì„œëŠ” â€œì—…ì¢… ì „ì²´ì˜ ì™¸êµ­ì¸ ë¹„ìœ¨â€ ê¸°ì¤€ì…ë‹ˆë‹¤.)\n",
      "\n",
      "1. ì‚¬ë¬´ ë° íšŒí™”ìš©í’ˆ ì œì¡°ì—… (33920)  \n",
      "   - ì™¸êµ­ì¸ 216ëª… / ì „ì²´ 854ëª… (ë¹„ìœ¨ ì•½ 25.3%)  \n",
      "   - ê³µì¥ ìˆ˜: 14ê°œ  \n",
      "   - íŠ¹ì§•: í•„ê¸°êµ¬, ë¯¸ìˆ ìš©í’ˆ, ë¬¸êµ¬ë¥˜ ë“± ì œì¡°. ë‹¨ìˆœÂ·ë°˜ë³µ ê³µì •ê³¼ ë¼ì¸ ì‘ì—…ì´ ë§ì•„ ì™¸êµ­ì¸ ì¸ë ¥ì´ ë§ì´ íˆ¬ì…ë˜ëŠ” ê²ƒìœ¼ë¡œ ë³´ì„.\n",
      "\n",
      "2. ê°€ë°© ë° ë³´í˜¸ìš© ì¼€ì´ìŠ¤ ë„ë§¤ì—… (46491)  \n",
      "   - ì™¸êµ­ì¸ 6ëª… / ì „ì²´ 24ëª… (ë¹„ìœ¨ 25%)  \n",
      "   - ê³µì¥ ìˆ˜: 1ê°œ  \n",
      "   - íŠ¹ì§•: ë„ë§¤ì—…ì´ì§€ë§Œ ë¬¼ë¥˜Â·í¬ì¥Â·ë‹¨ìˆœ ì‘ì—…ì— ì™¸êµ­ì¸ ì¸ë ¥ì´ í™œìš©ë˜ëŠ” ì‚¬ë¡€.\n",
      "\n",
      "3. ìœ¡ë¥˜ í¬ì¥ìœ¡ ë° ëƒ‰ë™ìœ¡ ê°€ê³µì—… (ê°€ê¸ˆë¥˜ ì œì™¸) (10122)  \n",
      "   - ì™¸êµ­ì¸ 33ëª… / ì „ì²´ 141ëª… (ë¹„ìœ¨ ì•½ 23.4%)  \n",
      "   - ê³µì¥ ìˆ˜: 6ê°œ  \n",
      "   - íŠ¹ì§•: ëƒ‰ë™Â·ì €ì˜¨ í™˜ê²½, ë°˜ë³µì ì¸ ê°€ê³µÂ·í¬ì¥ ì‘ì—… ë“± ê¸°í”¼ë„ê°€ ë†’ì€ 3D(Dirty, Difficult, Dangerous) ì„±ê²©ì´ ìˆì–´ ì™¸êµ­ì¸ ì˜ì¡´ë„ê°€ ë†’ì€ í¸.\n",
      "\n",
      "4. ì½˜í¬ë¦¬íŠ¸ íƒ€ì¼, ê¸°ì™€, ë²½ëŒ ë° ë¸”ë¡ ì œì¡°ì—… (23324)  \n",
      "   - ì™¸êµ­ì¸ 6ëª… / ì „ì²´ 36ëª… (ë¹„ìœ¨ 16.7%)  \n",
      "   - ê³µì¥ ìˆ˜: 3ê°œ  \n",
      "   - íŠ¹ì§•: ì•¼ì™¸Â·ì¤‘ëŸ‰ë¬¼ ì·¨ê¸‰ ë“± ìœ¡ì²´ë…¸ë™ ë¹„ì¤‘ì´ ë†’ì•„ ì™¸êµ­ì¸ ê·¼ë¡œì í™œìš©.\n",
      "\n",
      "5. ì—°ì‚¬ ë° ê°€ê³µì‚¬ ì œì¡°ì—… (13104)  \n",
      "   - ì™¸êµ­ì¸ 21ëª… / ì „ì²´ 150ëª… (ë¹„ìœ¨ 14%)  \n",
      "   - ê³µì¥ ìˆ˜: 8ê°œ  \n",
      "   - íŠ¹ì§•: ì„¬ìœ Â·ì‹¤ ê°€ê³µ ê³µì •, êµëŒ€ì œÂ·ì†ŒìŒÂ·ë¶„ì§„ ë“±ìœ¼ë¡œ ë‚´êµ­ì¸ ê¸°í”¼ ê²½í–¥ â†’ ì™¸êµ­ì¸ ë¹„ìœ¨ ìƒìŠ¹.\n",
      "\n",
      "6. ëˆ ë° ë¡œí”„ ì œì¡°ì—… (13921)  \n",
      "   - ì™¸êµ­ì¸ 6ëª… / ì „ì²´ 57ëª… (ë¹„ìœ¨ ì•½ 10.5%)  \n",
      "   - ê³µì¥ ìˆ˜: 5ê°œ  \n",
      "   - íŠ¹ì§•: ì†Œê·œëª¨ ì œì¡°ì—…, ë°˜ë³µ ê³µì • ì¤‘ì‹¬.\n",
      "\n",
      "7. ê¸ˆì† ì—´ì²˜ë¦¬ì—… (25921)  \n",
      "   - ì™¸êµ­ì¸ 9ëª… / ì „ì²´ 90ëª… (ë¹„ìœ¨ 10%)  \n",
      "   - ê³µì¥ ìˆ˜: 6ê°œ  \n",
      "   - íŠ¹ì§•: ê³ ì˜¨Â·ì•¼ê°„ì‘ì—… ë“± ì‘ì—…í™˜ê²½ì´ ê±°ì¹œ í¸ì´ë¼ ì™¸êµ­ì¸ ì¸ë ¥ ë¹„ì¤‘ì´ ì¡´ì¬.\n",
      "\n",
      "8. ê¸°íƒ€ ì˜¤ë½ìš©í’ˆ ì œì¡°ì—… (33409)  \n",
      "   - ì™¸êµ­ì¸ 9ëª… / ì „ì²´ 90ëª… (ë¹„ìœ¨ 10%)  \n",
      "   - ê³µì¥ ìˆ˜: 5ê°œ  \n",
      "   - íŠ¹ì§•: ì™„êµ¬Â·ê²Œì„ìš©í’ˆ ë“± ì¡°ë¦½Â·í¬ì¥ ìœ„ì£¼ì˜ ë¼ì¸ ì‘ì—….\n",
      "\n",
      "9. ì—¼ë£Œ, ì¡°ì œ ë¬´ê¸°ì•ˆë£Œ, ìœ ì—°ì œ ë° ê¸°íƒ€ ì°©ìƒ‰ì œ ì œì¡°ì—… (20132)  \n",
      "   - ì™¸êµ­ì¸ 6ëª… / ì „ì²´ 63ëª… (ë¹„ìœ¨ ì•½ 9.5%)  \n",
      "   - ê³µì¥ ìˆ˜: 3ê°œ  \n",
      "   - íŠ¹ì§•: í™”í•™ë¬¼ì§ˆ ì·¨ê¸‰, ì¥ì‹œê°„ ê·¼ë¬´ ë“±ìœ¼ë¡œ ë‚´êµ­ì¸ ê¸°í”¼ â†’ ì™¸êµ­ì¸ í™œìš©.\n",
      "\n",
      "10. ê¸°íƒ€ ì‚°ì—…ìš© ìœ ë¦¬ì œí’ˆ ì œì¡°ì—… (23129)  \n",
      "    - ì™¸êµ­ì¸ 12ëª… / ì „ì²´ 129ëª… (ë¹„ìœ¨ ì•½ 9.3%)  \n",
      "    - ê³µì¥ ìˆ˜: 5ê°œ  \n",
      "    - íŠ¹ì§•: ê³ ì˜¨Â·ì¤‘ëŸ‰ë¬¼Â·ë¼ì¸ ì‘ì—… ë“± ë¬¼ë¦¬ì  ë¶€ë‹´ì´ í° ê³µì • í¬í•¨.\n",
      "\n",
      "---\n",
      "\n",
      "## 3. ì •ë¦¬: ì™¸êµ­ì¸ ê·¼ë¡œìê°€ ë§ì€ ê³µì¥Â·ì—…ì¢…ì˜ ê³µí†µì \n",
      "\n",
      "ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ë³´ë©´:\n",
      "\n",
      "- **ì§€ì—­**: ì„œìš¸ ë‚´ì—ì„œë„ ì„±ë™êµ¬, ê¸ˆì²œêµ¬, êµ¬ë¡œêµ¬, ë™ëŒ€ë¬¸êµ¬ ë“± ê³µì¥ ë°€ì§‘ ì§€ì—­ì— ì™¸êµ­ì¸ ë¹„ìœ¨ ë†’ì€ ê³µì¥ì´ ì§‘ì¤‘.\n",
      "- **ì—…ì¢… ì„±ê²©**\n",
      "  - ë‹¨ìˆœÂ·ë°˜ë³µÂ·ë¼ì¸ ì‘ì—…ì´ ë§ì€ ì œì¡°ì—…\n",
      "  - ì‘ì—…í™˜ê²½ì´ í˜ë“¤ê±°ë‚˜(ê³ ì˜¨, ì €ì˜¨, ì†ŒìŒ, ë¶„ì§„, ì¤‘ëŸ‰ë¬¼) 3D ì—…ì¢…ì— í•´ë‹¹í•˜ëŠ” ë¶„ì•¼\n",
      "  - ì˜ë¥˜Â·ì„¬ìœ , ì‹í’ˆê°€ê³µ(ë–¡, ë„ì‹œë½, ìœ¡ë¥˜), í™”í•™, ê¸ˆì†Â·ìœ ë¦¬, ê°ì¢… ë¶€í’ˆÂ·ê¸°ê¸° ì œì¡° ë“±\n",
      "- **ê·œëª¨**\n",
      "  - ë¹„ìœ¨ë§Œ ë³´ë©´ ì†Œê·œëª¨ ê³µì¥ì—ì„œ 100% ì™¸êµ­ì¸ì¸ ê²½ìš°ê°€ ë§ê³ ,\n",
      "  - ì ˆëŒ€ ì¸ì› ìˆ˜ë¡œ ë³´ë©´ (ì£¼)ì§€êµ¬í™”í•™ì²˜ëŸ¼ ìˆ˜ë°± ëª… ê·œëª¨ ê³µì¥ë„ ì™¸êµ­ì¸ ë¹„ì¤‘ì´ ìƒë‹¹íˆ ë†’ìŒ.\n",
      "\n",
      "ì›í•˜ì‹œë©´  \n",
      "- â€œì„œìš¸ì—ì„œ ì™¸êµ­ì¸ ê·¼ë¡œì ë¹„ìœ¨ ë†’ì€ ê³µì¥ë§Œ ì§€ë„ì²˜ëŸ¼ ì •ë¦¬â€  \n",
      "- â€œì‹í’ˆ/ì„¬ìœ /ê¸°ê³„ ì¤‘ íŠ¹ì • ì—…ì¢…ë§Œ ë”°ë¡œ ë³´ê³  ì‹¶ë‹¤â€  \n",
      "ê°™ì´ ë” ì¢í˜€ì„œë„ ì •ë¦¬í•´ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "print(answer['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "359acc5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'ì„œìš¸ì˜ ì „ìë¶€í’ˆ ì—…ì¢…ì˜ ê³µì¥ìˆ˜ë¥¼ ì•Œë ¤ì¤˜',\n",
       " 'q_type': 'domain_specific',\n",
       " 'answer': 'ì„œìš¸ ì§€ì—­ì—ì„œ **ì—…ì¢…ì— â€˜ì „ìë¶€í’ˆâ€™ì´ í¬í•¨ëœ ê³µì¥ ìˆ˜ëŠ” ì´ 295ê°œ**ì…ë‹ˆë‹¤.',\n",
       " 'session_id': 'aaa'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = RunnableConfig(recursion_limit=20, configurable={\"session_id\": \"1\", \"thread_id\": uuid.uuid4().hex})  \n",
    "\n",
    "question = (\n",
    "    \"ì„œìš¸ì˜ ì „ìë¶€í’ˆ ì—…ì¢…ì˜ ê³µì¥ìˆ˜ë¥¼ ì•Œë ¤ì¤˜\"\n",
    ")\n",
    "\n",
    "inputs = GraphState(\n",
    "    question=question,\n",
    "    session_id='aaa',\n",
    "    q_type='',\n",
    "    answer='',\n",
    ")\n",
    "\n",
    "answer = graph.invoke(inputs, config=config)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b41fc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeongyunl/Documents/GitHub/factory-chatbot-demo/backend/main.py:58: DtypeWarning: Columns (11,13,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('data/cleaned_ì „êµ­ê³µì¥ë“±ë¡í˜„í™©_preprocessed_seoul.csv')\n"
     ]
    }
   ],
   "source": [
    "from main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a745fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ†• ìƒˆë¡œìš´ ì„¸ì…˜ íˆìŠ¤í† ë¦¬ ìƒì„±: aaa...\n",
      "ğŸ†• ìƒˆë¡œìš´ ì„¸ì…˜ íˆìŠ¤í† ë¦¬ ìƒì„±: session_...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: ValueError(\"Expected str, BaseMessage, List[BaseMessage], or Tuple[BaseMessage]. Got {'q_type': 'domain_specific', 'question': 'ì„œìš¸ì—ì„œ ê³µì¥ì´ ê°€ì¥ ë§ì€ êµ¬ëŠ” ì–´ë””ì•¼?'}.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'ì„œìš¸ì—ì„œ ê³µì¥ì´ ê°€ì¥ ë§ì€ êµ¬ëŠ” ì–´ë””ì•¼?',\n",
       " 'q_type': 'domain_specific',\n",
       " 'answer': 'ë°ì´í„°ì— ë”°ë¥´ë©´ ì„œìš¸ì—ì„œ ê³µì¥ì´ ê°€ì¥ ë§ì€ êµ¬ëŠ” **ê¸ˆì²œêµ¬**ì´ë©°, ê³µì¥ ìˆ˜ëŠ” **4,059ê°œ**ì…ë‹ˆë‹¤.',\n",
       " 'session_id': 'aaa'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = RunnableConfig(recursion_limit=20, configurable={\"session_id\": \"1\", \"thread_id\": uuid.uuid4().hex})  \n",
    "\n",
    "question = (\n",
    "    \"ì„œìš¸ì—ì„œ ê³µì¥ì´ ê°€ì¥ ë§ì€ êµ¬ëŠ” ì–´ë””ì•¼?\"\n",
    ")\n",
    "\n",
    "inputs = GraphState(\n",
    "    question=question,\n",
    "    session_id='aaa',\n",
    "    q_type='',\n",
    "    answer='',\n",
    ")\n",
    "\n",
    "answer = graph.invoke(inputs, config=config)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5074dd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ†• ìƒˆë¡œìš´ ì„¸ì…˜ íˆìŠ¤í† ë¦¬ ìƒì„±: aaa...\n",
      "ğŸ†• ìƒˆë¡œìš´ ì„¸ì…˜ íˆìŠ¤í† ë¦¬ ìƒì„±: session_...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: ValueError(\"Expected str, BaseMessage, List[BaseMessage], or Tuple[BaseMessage]. Got {'question': 'ìµœê·¼ 5ë…„ê°„ ì„œìš¸ ì „ì²´ ê³µì¥ ë“±ë¡ ê±´ìˆ˜ ì¶”ì´ë¥¼ ë³´ì—¬ì¤˜', 'q_type': 'domain_specific'}.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'ìµœê·¼ 5ë…„ê°„ ì„œìš¸ ì „ì²´ ê³µì¥ ë“±ë¡ ê±´ìˆ˜ ì¶”ì´ë¥¼ ë³´ì—¬ì¤˜',\n",
       " 'q_type': 'domain_specific',\n",
       " 'answer': 'ìµœê·¼ 5ë…„(ì˜¤ëŠ˜ ê¸°ì¤€ 5ë…„ ì „ë¶€í„°) ë™ì•ˆ ì„œìš¸íŠ¹ë³„ì‹œ ì „ì²´ ê³µì¥ ë“±ë¡ ê±´ìˆ˜ ì¶”ì´ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\\n\\n- 2020ë…„: 56ê°œ\\n- 2021ë…„: 653ê°œ\\n- 2022ë…„: 551ê°œ\\n- 2023ë…„: 436ê°œ\\n- 2024ë…„: 495ê°œ  \\n- 2025ë…„: 357ê°œ (ì§„í–‰ ì¤‘ ì—°ë„, í˜„ì¬ê¹Œì§€ ì§‘ê³„ì¹˜)\\n\\nâ€» 2025ë…„ì€ ì•„ì§ ì—°ë„ê°€ ëë‚˜ì§€ ì•Šì•„, í–¥í›„ ì‹¤ì œ ì—°ê°„ ë“±ë¡ ê±´ìˆ˜ëŠ” ë” ëŠ˜ì–´ë‚  ìˆ˜ ìˆìŠµë‹ˆë‹¤.',\n",
       " 'session_id': 'aaa'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = RunnableConfig(recursion_limit=20, configurable={\"session_id\": \"1\", \"thread_id\": uuid.uuid4().hex})  \n",
    "\n",
    "question = (\n",
    "    \"ìµœê·¼ 5ë…„ê°„ ì„œìš¸ ì „ì²´ ê³µì¥ ë“±ë¡ ê±´ìˆ˜ ì¶”ì´ë¥¼ ë³´ì—¬ì¤˜\"\n",
    ")\n",
    "\n",
    "inputs = GraphState(\n",
    "    question=question,\n",
    "    session_id='aaa',\n",
    "    q_type='',\n",
    "    answer='',\n",
    ")\n",
    "\n",
    "answer = graph.invoke(inputs, config=config)\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f52ba3",
   "metadata": {},
   "source": [
    "# ver2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d91f84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3k/09hbppyx33z8tmqmvw42bgqm0000gn/T/ipykernel_21420/3578754156.py:48: DtypeWarning: Columns (11,13,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('data/cleaned_ì „êµ­ê³µì¥ë“±ë¡í˜„í™©_preprocessed_seoul.csv')\n"
     ]
    }
   ],
   "source": [
    "import uuid, os, io, sys, time, json\n",
    "from datetime import datetime, date\n",
    "import threading\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import wraps\n",
    "\n",
    "from openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.errors import GraphRecursionError\n",
    "\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory, StreamlitChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langgraph.graph.message import add_messages\n",
    "from operator import itemgetter\n",
    "\n",
    "from langchain.agents import tool\n",
    "from langchain.agents import create_tool_calling_agent\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# from langchain_teddynote import logging\n",
    "from langsmith import traceable\n",
    "import threading\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv(override=True)\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in environment variables\")\n",
    "\n",
    "# ëª¨ë¸\n",
    "model = ChatOpenAI(\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    model=\"gpt-5.1-2025-11-13\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "df = pd.read_csv('data/cleaned_ì „êµ­ê³µì¥ë“±ë¡í˜„í™©_preprocessed_seoul.csv')\n",
    "\n",
    "###################################################################################################\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    question: str  # ì§ˆë¬¸\n",
    "    q_type: str  # ì§ˆë¬¸ì˜ ìœ í˜•\n",
    "    answer: str | list[str]  # llmì´ ìƒì„±í•œ ë‹µë³€\n",
    "    session_id: str  # ì„¸ì…˜ ID\n",
    "    context: str | None  # ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸\n",
    "    relevance: str | None  # ê²€ìƒ‰ ì í•©ë„\n",
    "    execution_id: str | None  # ì‹¤í–‰ ê²°ê³¼ ì‹ë³„ì\n",
    "\n",
    "# ìŠ¤ë ˆë“œ ì €ì¥ì†Œ\n",
    "class ThreadSafeStore:\n",
    "    def __init__(self):\n",
    "        self._store = {}\n",
    "        self._lock = threading.RLock()  # ì¬ì§„ì… ê°€ëŠ¥í•œ ë½\n",
    "    \n",
    "    def get_session_history(self, session_id: str):\n",
    "        with self._lock:\n",
    "            if session_id not in self._store:\n",
    "                self._store[session_id] = ChatMessageHistory()\n",
    "                print(f\"ğŸ†• ìƒˆë¡œìš´ ì„¸ì…˜ íˆìŠ¤í† ë¦¬ ìƒì„±: {session_id[:8]}...\")\n",
    "            return self._store[session_id]\n",
    "    \n",
    "    def clear_session(self, session_id: str = None):\n",
    "        with self._lock:\n",
    "            if session_id:\n",
    "                if session_id in self._store:\n",
    "                    message_count = len(self._store[session_id].messages)\n",
    "                    del self._store[session_id]\n",
    "                    return message_count\n",
    "                return 0\n",
    "            else:\n",
    "                total_sessions = len(self._store)\n",
    "                total_messages = sum(len(history.messages) for history in self._store.values())\n",
    "                self._store.clear()\n",
    "                return total_sessions, total_messages\n",
    "    \n",
    "    def get_stats(self):\n",
    "        with self._lock:\n",
    "            return {\n",
    "                'total_sessions': len(self._store),\n",
    "                'total_messages': sum(len(history.messages) for history in self._store.values())\n",
    "            }\n",
    "\n",
    "# ì „ì—­ ìŠ¤ë ˆë“œ ì•ˆì „ ì €ì¥ì†Œ\n",
    "thread_safe_store = ThreadSafeStore()\n",
    "\n",
    "# ì„¸ì…˜ IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\n",
    "def get_session_history(session_ids):\n",
    "    return thread_safe_store.get_session_history(session_ids)\n",
    "\n",
    "# ìƒˆë¡œìš´ ì„¸ì…˜ ID ìƒì„± í•¨ìˆ˜\n",
    "def generate_session_id():\n",
    "    return str(uuid.uuid4())\n",
    "\n",
    "class ExecutionResultStore:\n",
    "    def __init__(self):\n",
    "        self._store = {}\n",
    "        self._lock = threading.RLock()\n",
    "\n",
    "    def save(self, session_id: str, code: str | None, output, question: str = \"\"):\n",
    "        execution_id = str(uuid.uuid4())\n",
    "        payload = {\n",
    "            \"execution_id\": execution_id,\n",
    "            \"session_id\": session_id,\n",
    "            \"code\": code,\n",
    "            \"result\": serialize_execution_output(output, question),\n",
    "            \"created_at\": time.time()\n",
    "        }\n",
    "        with self._lock:\n",
    "            self._store[execution_id] = payload\n",
    "        return execution_id\n",
    "\n",
    "    def get(self, execution_id: str):\n",
    "        with self._lock:\n",
    "            return self._store.get(execution_id)\n",
    "\n",
    "\n",
    "def ensure_json_serializable(value):\n",
    "    if isinstance(value, (np.integer, np.int32, np.int64)):\n",
    "        return int(value)\n",
    "    if isinstance(value, (np.floating, np.float32, np.float64)):\n",
    "        return float(value)\n",
    "    if isinstance(value, (np.bool_,)):\n",
    "        return bool(value)\n",
    "    if isinstance(value, (list, tuple)):\n",
    "        return [ensure_json_serializable(v) for v in value]\n",
    "    if isinstance(value, dict):\n",
    "        return {k: ensure_json_serializable(v) for k, v in value.items()}\n",
    "    if isinstance(value, (pd.Timestamp,)):\n",
    "        return value.isoformat()\n",
    "    if isinstance(value, np.datetime64):\n",
    "        return pd.Timestamp(value).isoformat()\n",
    "    if isinstance(value, (datetime, date)):\n",
    "        return value.isoformat()\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "    return value\n",
    "\n",
    "\n",
    "def dataframe_to_rows(df: pd.DataFrame, limit: int = 50):\n",
    "    preview_df = df.head(limit).copy()\n",
    "    preview_df = preview_df.where(pd.notnull(preview_df), None)\n",
    "    records = preview_df.to_dict(orient=\"records\")\n",
    "    return [ensure_json_serializable(record) for record in records]\n",
    "\n",
    "\n",
    "class VisualizationRecommendation(BaseModel):\n",
    "    chart_type: str = Field(description=\"Recommended chart type. Choose from ['bar_chart', 'line_chart', 'pie_chart', 'map', 'heatmap', 'scatter_plot', 'none']\")\n",
    "    x_axis: str | None = Field(default=None, description=\"Column name for x-axis\")\n",
    "    y_axis: str | None = Field(default=None, description=\"Column name for y-axis\")\n",
    "    orientation: str | None = Field(default=None, description=\"For bar chart: 'horizontal' or 'vertical'\")\n",
    "    has_location: bool = Field(default=False, description=\"Whether the data contains location information suitable for map visualization\")\n",
    "    group_by: str | None = Field(default=None, description=\"Column name for grouping data\")\n",
    "    time_series: bool = Field(default=False, description=\"Whether the data is time-series data\")\n",
    "\n",
    "visualization_output_parser = JsonOutputParser(pydantic_object=VisualizationRecommendation)\n",
    "visualization_format_instructions = visualization_output_parser.get_format_instructions()\n",
    "\n",
    "visualization_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    You are an expert data visualization analyst. Analyze the user's question and the data structure to recommend the best visualization type.\n",
    "\n",
    "    Available chart types:\n",
    "    - 'bar_chart': For comparing categories (e.g., \"êµ¬ë³„ ê³µì¥ ìˆ˜\", \"ì—…ì¢…ë³„ ì§ì› ìˆ˜\")\n",
    "    - 'line_chart': For showing trends over time (e.g., \"ì—°ë„ë³„ ë“±ë¡ ê±´ìˆ˜ ì¶”ì´\", \"ìµœê·¼ 5ë…„ê°„ ë³€í™”\")\n",
    "    - 'pie_chart': For showing proportions/percentages (e.g., \"ì—…ì¢…ë³„ ë¹„ìœ¨\", \"ê·œëª¨ë³„ ë¶„í¬\")\n",
    "    - 'map': For location-based data (e.g., \"êµ¬ë³„ ê³µì¥ ë¶„í¬\", \"ì§€ì—­ë³„ ë¶„ì„\")\n",
    "    - 'heatmap': For 2D cross-tabulation (e.g., \"êµ¬ë³„ ì—…ì¢…ë³„ ê³µì¥ ìˆ˜\")\n",
    "    - 'scatter_plot': For correlation between two numeric variables (e.g., \"ë©´ì  ëŒ€ë¹„ ì§ì› ìˆ˜\")\n",
    "    - 'none': When visualization is not suitable or data is too complex\n",
    "\n",
    "    Data columns available: {columns}\n",
    "    User question: {question}\n",
    "    Data sample (first 3 rows): {sample_data}\n",
    "\n",
    "    Consider:\n",
    "    1. If the question mentions location (êµ¬, ì‹œêµ°êµ¬, ì§€ì—­, ì§€ë„), recommend 'map' if location columns exist\n",
    "    2. If the question mentions time/trend (ì¶”ì´, ë³€í™”, ì—°ë„, ë…„ë„), recommend 'line_chart'\n",
    "    3. If the question asks for comparison (ë¹„êµ, ìƒìœ„, ë§ë‹¤), recommend 'bar_chart'\n",
    "    4. If the question asks for proportion/ratio (ë¹„ìœ¨, ë¶„í¬), recommend 'pie_chart'\n",
    "    5. If data has 2 categorical dimensions, consider 'heatmap'\n",
    "    6. If data has 2 numeric variables for correlation, consider 'scatter_plot'\n",
    "\n",
    "    {format_instructions}\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"columns\", \"sample_data\"],\n",
    "    partial_variables={\"format_instructions\": visualization_format_instructions},\n",
    ")\n",
    "\n",
    "\n",
    "def infer_visualization_type(question: str, output) -> dict | None:\n",
    "    \"\"\"\n",
    "    ì§ˆë¬¸ê³¼ ê²°ê³¼ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì‹œê°í™” íƒ€ì…ì„ ì¶”ë¡ í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # DataFrame ë˜ëŠ” Seriesì¸ ê²½ìš°ì—ë§Œ ì‹œê°í™” ì¶”ë¡ \n",
    "        if not isinstance(output, (pd.DataFrame, pd.Series)):\n",
    "            return None\n",
    "        \n",
    "        # Seriesë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "        if isinstance(output, pd.Series):\n",
    "            df_for_analysis = output.reset_index()\n",
    "        else:\n",
    "            df_for_analysis = output.copy()\n",
    "        \n",
    "        # ë°ì´í„°ê°€ ë¹„ì–´ìˆìœ¼ë©´ None ë°˜í™˜\n",
    "        if len(df_for_analysis) == 0:\n",
    "            return None\n",
    "        \n",
    "        # ì»¬ëŸ¼ì´ ë„ˆë¬´ ë§ìœ¼ë©´ ì‹œê°í™” ë¹„ì¶”ì²œ\n",
    "        if len(df_for_analysis.columns) > 10:\n",
    "            return {\"chart_type\": \"none\"}\n",
    "        \n",
    "        # ìƒ˜í”Œ ë°ì´í„° ì¤€ë¹„ (ìµœëŒ€ 3í–‰)\n",
    "        sample_df = df_for_analysis.head(3)\n",
    "        sample_data = sample_df.to_dict(orient=\"records\")\n",
    "        \n",
    "        # ì»¬ëŸ¼ ëª©ë¡\n",
    "        columns = list(df_for_analysis.columns)\n",
    "        \n",
    "        # LLMì„ ì‚¬ìš©í•˜ì—¬ ì‹œê°í™” íƒ€ì… ì¶”ë¡ \n",
    "        chain = visualization_prompt | model | visualization_output_parser\n",
    "        \n",
    "        result = chain.invoke({\n",
    "            \"question\": question,\n",
    "            \"columns\": str(columns),\n",
    "            \"sample_data\": str(sample_data)\n",
    "        })\n",
    "        \n",
    "        # ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜\n",
    "        visualization_meta = {\n",
    "            \"chart_type\": result.get(\"chart_type\", \"none\"),\n",
    "            \"x_axis\": result.get(\"x_axis\"),\n",
    "            \"y_axis\": result.get(\"y_axis\"),\n",
    "            \"orientation\": result.get(\"orientation\", \"vertical\"),\n",
    "            \"has_location\": result.get(\"has_location\", False),\n",
    "            \"group_by\": result.get(\"group_by\"),\n",
    "            \"time_series\": result.get(\"time_series\", False)\n",
    "        }\n",
    "        \n",
    "        # ì‹¤ì œ ë°ì´í„° êµ¬ì¡°ì— ë§ê²Œ ì¶• ì •ë³´ ë³´ì •\n",
    "        if visualization_meta[\"chart_type\"] != \"none\":\n",
    "            # x_axisê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ê³  DataFrameì¸ ê²½ìš° ì²« ë²ˆì§¸ ì»¬ëŸ¼ ì‚¬ìš©\n",
    "            if not visualization_meta[\"x_axis\"] and len(columns) > 0:\n",
    "                if isinstance(output, pd.Series):\n",
    "                    visualization_meta[\"x_axis\"] = \"index\"\n",
    "                    visualization_meta[\"y_axis\"] = \"value\"\n",
    "                else:\n",
    "                    # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì´ ì¸ë±ìŠ¤ ì»¬ëŸ¼ì¸ ê²½ìš°\n",
    "                    if columns[0] in [\"index\", \"ì •ì œ_ì‹œêµ°êµ¬ëª…\", \"ì •ì œ_ì—…ì¢…ëª…\"]:\n",
    "                        visualization_meta[\"x_axis\"] = columns[0]\n",
    "                    # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ì°¾ê¸°\n",
    "                    numeric_cols = df_for_analysis.select_dtypes(include=[np.number]).columns.tolist()\n",
    "                    if numeric_cols:\n",
    "                        visualization_meta[\"y_axis\"] = numeric_cols[0]\n",
    "            \n",
    "            # ìœ„ì¹˜ ì •ë³´ í™•ì¸\n",
    "            location_cols = [col for col in columns if any(keyword in col for keyword in [\"ì‹œêµ°êµ¬\", \"ì‹œë„\", \"êµ¬\", \"ì§€ì—­\", \"ì£¼ì†Œ\"])]\n",
    "            if location_cols:\n",
    "                visualization_meta[\"has_location\"] = True\n",
    "                if not visualization_meta[\"x_axis\"]:\n",
    "                    visualization_meta[\"x_axis\"] = location_cols[0]\n",
    "        \n",
    "        return visualization_meta\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ì‹œê°í™” íƒ€ì… ì¶”ë¡  ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def serialize_execution_output(output, question: str = \"\"):\n",
    "    # ì‹œê°í™” ë©”íƒ€ë°ì´í„° ì¶”ë¡ \n",
    "    visualization_meta = infer_visualization_type(question, output) if question else None\n",
    "    \n",
    "    if isinstance(output, pd.DataFrame):\n",
    "        result = {\n",
    "            \"type\": \"table\",\n",
    "            \"columns\": list(output.columns),\n",
    "            \"rows\": dataframe_to_rows(output),\n",
    "            \"row_count\": int(len(output))\n",
    "        }\n",
    "        if visualization_meta:\n",
    "            result[\"visualization\"] = visualization_meta\n",
    "        return result\n",
    "    if isinstance(output, pd.Series):\n",
    "        series_df = output.reset_index()\n",
    "        series_df.columns = [\"index\", \"value\"]\n",
    "        result = {\n",
    "            \"type\": \"table\",\n",
    "            \"columns\": list(series_df.columns),\n",
    "            \"rows\": dataframe_to_rows(series_df),\n",
    "            \"row_count\": int(len(output))\n",
    "        }\n",
    "        if visualization_meta:\n",
    "            result[\"visualization\"] = visualization_meta\n",
    "        return result\n",
    "    if isinstance(output, (list, tuple)):\n",
    "        return {\n",
    "            \"type\": \"list\",\n",
    "            \"rows\": [ensure_json_serializable(item) for item in output],\n",
    "            \"row_count\": len(output)\n",
    "        }\n",
    "    if isinstance(output, dict):\n",
    "        return {\n",
    "            \"type\": \"object\",\n",
    "            \"data\": ensure_json_serializable(output)\n",
    "        }\n",
    "    if output is None:\n",
    "        return {\n",
    "            \"type\": \"text\",\n",
    "            \"value\": None\n",
    "        }\n",
    "    return {\n",
    "        \"type\": \"text\",\n",
    "        \"value\": str(output)\n",
    "    }\n",
    "\n",
    "\n",
    "execution_store = ExecutionResultStore()\n",
    "\n",
    "#######################################################################\n",
    "############################ nodes: Router ############################\n",
    "#######################################################################\n",
    "\n",
    "class Router(BaseModel):\n",
    "    type: str = Field(description=\"type of the query that model choose. Choose from ['general', 'domain_specific']\")\n",
    "\n",
    "router_output_parser = JsonOutputParser(pydantic_object=Router)\n",
    "router_format_instructions = router_output_parser.get_format_instructions()\n",
    "\n",
    "router_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "            You are an expert who classifies the type of question. There are two query types: ['general', 'domain_specific']\n",
    "\n",
    "            [general]\n",
    "            Questions unrelated to data query, such as translating English to Korean, asking for general knowledge (e.g., \"What is the capital of South Korea?\"), or queries that can be answered through a web search.\n",
    "\n",
    "            [domain_specific]\n",
    "            Questions related to 'factory' domain and data query, such as 'count the unique values of factories in Seoul', or count 'the number of rows in a table'.\n",
    "\n",
    "            <Output format>: Always respond with either \"general\" or \"domain_specific\" and nothing else. {format_instructions}\n",
    "            <chat_history>: {chat_history}\n",
    "            \n",
    "            <Question>: {query} \n",
    "            \"\"\",\n",
    "    input_variables=[\"query\", \"chat_history\"],\n",
    "    partial_variables={\"format_instructions\": router_format_instructions},\n",
    ")\n",
    "\n",
    "def router(state: GraphState) -> GraphState:\n",
    "    chain = router_prompt | model | router_output_parser\n",
    "    \n",
    "    router_with_history  = RunnableWithMessageHistory(\n",
    "        chain,\n",
    "        get_session_history,\n",
    "        input_messages_key=\"query\",\n",
    "        history_messages_key=\"chat_history\",\n",
    "    )\n",
    "    \n",
    "    router_result = router_with_history.invoke(\n",
    "        {\"query\": state[\"question\"]}, \n",
    "        {'configurable': {'session_id': state[\"session_id\"]}}\n",
    "    )\n",
    "    state[\"q_type\"] = router_result['type']\n",
    "    return state\n",
    "\n",
    "def router_conditional_edge(state: GraphState) -> GraphState:\n",
    "    q_type = state[\"q_type\"].strip()\n",
    "    return q_type\n",
    "\n",
    "##################################################################################\n",
    "###################### nodes: Generate Python Pandas Code ########################\n",
    "##################################################################################\n",
    "\n",
    "class CodeGenerator(BaseModel):\n",
    "    code: str = Field(description=\"Python Pandas Code\")\n",
    "\n",
    "code_generator_output_parser = JsonOutputParser(pydantic_object=CodeGenerator)\n",
    "code_generator_format_instructions = code_generator_output_parser.get_format_instructions()\n",
    "\n",
    "code_generator_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "            You are an expert who can generate Python Pandas Code to answer the query.\n",
    "\n",
    "            Write the code with the following dataset metadata. Do not use any other columns except the ones provided in the metadata. The columns are written in Korean.\n",
    "\n",
    "            <Dataset Metadata>: \n",
    "            # Basic Information\n",
    "            1. 'ê³µì¥ê´€ë¦¬ë²ˆí˜¸' (Factory Management Number): Unique factory identification number. [Important] A single factory management number can appear across multiple rows. When counting the number of factories, always use unique/distinct values of this field.\n",
    "\n",
    "            # Company & Factory Information\n",
    "            2. 'íšŒì‚¬ëª…' (Company Name): Name of the company operating the factory. It's not unique. \n",
    "            3. 'ê³µì¥êµ¬ë¶„' (Factory Classification): Type/classification of the factory. categorized by \n",
    "            4. 'ë‹¨ì§€ëª…' (Complex Name): Name of the industrial complex (if applicable)\n",
    "            5. 'ì„¤ë¦½êµ¬ë¶„' (Establishment Type): Classification of how the factory was established\n",
    "            6. 'ì…ì£¼í˜•íƒœ' (Occupancy Type): Type of occupancy arrangement\n",
    "            7. 'ë“±ë¡êµ¬ë¶„' (Registration Type): Classification of factory registration\n",
    "            8. 'ì „í™”ë²ˆí˜¸' (Phone Number): Contact phone number\n",
    "\n",
    "\n",
    "            # Employee Statistics\n",
    "            9. 'ë‚¨ìì¢…ì—…ì›' (Male Employees): Number of male employees\n",
    "            10. 'ì—¬ìì¢…ì—…ì›' (Female Employees): Number of female employees\n",
    "            11. 'ì™¸êµ­ì¸ë‚¨ìì¢…ì—…ì›' (Foreign Male Employees): Number of foreign male employees\n",
    "            12. 'ì™¸êµ­ì¸ì—¬ìì¢…ì—…ì›' (Foreign Female Employees): Number of foreign female employees\n",
    "            13. 'ì¢…ì—…ì›í•©ê³„' (Total Employees): Total number of employees\n",
    "\n",
    "            # Production Information\n",
    "            14. 'ìƒì‚°í’ˆ' (Products): Products manufactured at the factory. It's not categorized and normalized, so you need use 'str.contains' to filter the products.\n",
    "            15. 'ì›ìì¬' (Raw Materials): Raw materials used in production. It's not categorized and normalized, so you need use 'str.contains' to filter the products.\n",
    "            16. 'ê³µì¥ê·œëª¨' (Factory Scale): Size classification of the factory. e.g. ['ì†Œê¸°ì—…', 'ì¤‘ê¸°ì—…', 'ëŒ€ê¸°ì—…', 'ì¤‘ê²¬ê¸°ì—…']\n",
    "            \n",
    "            # Facility Specifications\n",
    "            17. 'ìš©ì§€ë©´ì ' (Land Area): Total land area in square meters\n",
    "            18. 'ì œì¡°ì‹œì„¤ë©´ì ' (Manufacturing Facility Area): Area dedicated to manufacturing facilities\n",
    "            19. 'ë¶€ëŒ€ì‹œì„¤ë©´ì ' (Auxiliary Facility Area): Area of auxiliary/support facilities\n",
    "            20. 'ê±´ì¶•ë©´ì ' (Building Area): Total building area\n",
    "            21. 'ì§€ì‹ì‚°ì—…ì„¼í„°ëª…' (Knowledge Industry Center Name): Name of knowledge industry center (if applicable)\n",
    "\n",
    "            # Location & Administrative\n",
    "            22. 'í•„ì§€ìˆ˜' (Number of Parcels): Number of land parcels\n",
    "            23. 'ê³µì¥ê´€ë¦¬ë²ˆí˜¸' (Factory Management Number): Unique factory identification number\n",
    "\n",
    "            #Standardized Fields (ì •ì œ_)\n",
    "            24. 'ì •ì œ_ê´€ë¦¬ê¸°ê´€' (Standardized Management Agency): Standardized name of the management agency \n",
    "            25. 'ì •ì œ_ë³´ìœ êµ¬ë¶„' (Standardized Ownership Type): Standardized ownership classification\n",
    "            26. 'ì •ì œ_ì‹œêµ°êµ¬ëª…' (Standardized District Name): Standardized city/county/district name\n",
    "            27. 'ì •ì œ_ì‹œë„ëª…' (Standardized Province Name): Standardized province/metropolitan city name\n",
    "            28. 'ì •ì œ_ì—…ì¢…ëª…' (Standardized Industry Name): Standardized industry name. It's not unique, so you need to calculate with 'ì •ì œ_ëŒ€í‘œì—…ì¢…' and show in 'ì •ì œ_ì—…ì¢…ëª…'\n",
    "            29. 'ì •ì œ_ëŒ€í‘œì—…ì¢…' (Standardized Primary Industry): Standardized primary industry classification. It's in code, so after use it, you need to show the name using 'ì •ì œ_ëŒ€í‘œì—…ì¢…'\n",
    "            29. 'ì •ì œ_ìš©ë„ì§€ì—­' (Standardized Zoning District): Standardized zoning/land use district\n",
    "            30. 'ì •ì œ_ì§€ëª©' (Standardized Land Category): Standardized land category classification\n",
    "\n",
    "            # Date Fields\n",
    "            31. 'ì •ì œ_ìµœì´ˆë“±ë¡ì¼' (Standardized Initial Registration Date): Standardized date of initial registration (format: YYYY-MM-DD)\n",
    "            32. 'ì •ì œ_ìµœì´ˆìŠ¹ì¸ì¼' (Standardized Initial Approval Date): Standardized date of initial approval (format: YYYY-MM-DD)\n",
    "\n",
    "            Write the code with the most efficient way.\n",
    "            <Output format>: Always respond with Python Pandas code. Always assign the final result to a variable called `return_var`. Do not use print(). {format_instructions}\n",
    "            <chat_history>: {chat_history}\n",
    "            \n",
    "            <Question>: {query} \n",
    "            \"\"\",\n",
    "    input_variables=[\"query\", \"chat_history\"],\n",
    "    partial_variables={\"format_instructions\": code_generator_format_instructions},\n",
    ")\n",
    "\n",
    "@tool\n",
    "def code_generator(input, session_id: str | None = None):\n",
    "    \"\"\"\n",
    "    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ CSVì—ì„œ ì¿¼ë¦¬í•  ìˆ˜ ìˆëŠ” Python Pandas ì½”ë“œë¥¼ ì‘ì„±í•˜ëŠ” ë„êµ¬\n",
    "    \"\"\"\n",
    "    chain = code_generator_prompt | model | code_generator_output_parser\n",
    "\n",
    "    resolved_session_id = session_id or generate_session_id()\n",
    "\n",
    "    code_generator_with_history = RunnableWithMessageHistory(\n",
    "        chain,\n",
    "        get_session_history,\n",
    "        input_messages_key=\"query\",\n",
    "        history_messages_key=\"chat_history\",\n",
    "    )\n",
    "\n",
    "    code_generator_result = code_generator_with_history.invoke(\n",
    "        {\"query\": input},\n",
    "        {'configurable': {'session_id': resolved_session_id}}\n",
    "    )\n",
    "    return code_generator_result['code']\n",
    "\n",
    "@tool\n",
    "def code_executor(input_code: str, max_retries=3):\n",
    "    \"\"\"\n",
    "    LLMì´ ìƒì„±í•œ Pandas ì½”ë“œë¥¼ ì•ˆì „í•˜ê²Œ ì‹¤í–‰í•˜ê³  return_var ë°˜í™˜.\n",
    "    dfëŠ” ê¸€ë¡œë²Œ ë³€ìˆ˜ ì‚¬ìš©.\n",
    "    NA, None, 0 ë“±ì˜ ì—ëŸ¬ ëŒ€ë¹„.\n",
    "    \"\"\"\n",
    "    global df\n",
    "    local_vars = {'df': df}\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            exec(input_code, local_vars)\n",
    "            if 'return_var' not in local_vars:\n",
    "                raise ValueError(\"Generated code did not assign value to 'return_var'.\")\n",
    "            return local_vars['return_var']\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ ì½”ë“œ ì‹¤í–‰ ì‹¤íŒ¨ (ì‹œë„ {attempt+1}/{max_retries}): {e}\")\n",
    "            # NAë‚˜ boolean ë¹„êµ ì—ëŸ¬ ë“± ì¬ì‹œë„ ê°€ëŠ¥\n",
    "            if attempt == max_retries - 1:\n",
    "                raise\n",
    "\n",
    "############################ tools & Agents ############################\n",
    "\n",
    "# ğŸ”§ ê°œì„  3: OpenAI API ë ˆì´íŠ¸ ë¦¬ë¯¸íŒ… ë° ì¬ì‹œë„\n",
    "import openai\n",
    "from openai import RateLimitError, APITimeoutError\n",
    "\n",
    "def retry_on_failure(max_retries=3, delay=1):\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            last_exception = None\n",
    "            for attempt in range(max_retries):\n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "                except Exception as e:\n",
    "                    last_exception = e\n",
    "                    if attempt < max_retries - 1:\n",
    "                        print(f\"âš ï¸ ì‹œë„ {attempt + 1} ì‹¤íŒ¨, {delay}ì´ˆ í›„ ì¬ì‹œë„: {str(e)[:100]}\")\n",
    "                        time.sleep(delay * (attempt + 1))  # ì§€ìˆ˜ ë°±ì˜¤í”„\n",
    "                    else:\n",
    "                        print(f\"âŒ ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨: {str(e)}\")\n",
    "            raise last_exception\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "@retry_on_failure(max_retries=3, delay=2)\n",
    "def call_openai_with_retry(client, **kwargs):\n",
    "    try:\n",
    "        return client.chat.completions.create(**kwargs)\n",
    "    except RateLimitError as e:\n",
    "        print(f\"âš ï¸ OpenAI ë ˆì´íŠ¸ ë¦¬ë¯¸íŠ¸: {e}\")\n",
    "        time.sleep(5)  # ë ˆì´íŠ¸ ë¦¬ë¯¸íŠ¸ ì‹œ ë” ì˜¤ë˜ ëŒ€ê¸°\n",
    "        raise\n",
    "    except APITimeoutError as e:\n",
    "        print(f\"âš ï¸ OpenAI íƒ€ì„ì•„ì›ƒ: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ OpenAI API ì˜¤ë¥˜: {e}\")\n",
    "        raise\n",
    "    \n",
    "tools = [code_generator, code_executor]\n",
    "\n",
    "def capture_execution_snapshot(session_id: str, intermediate_steps, question: str = \"\") -> str | None:\n",
    "    if not intermediate_steps:\n",
    "        return None\n",
    "\n",
    "    code_snippet = None\n",
    "    execution_output = None\n",
    "\n",
    "    for step in intermediate_steps:\n",
    "        try:\n",
    "            action, observation = step\n",
    "        except (TypeError, ValueError):\n",
    "            continue\n",
    "\n",
    "        tool_name = getattr(action, \"tool\", None)\n",
    "\n",
    "        if tool_name == \"code_generator\" and isinstance(observation, str):\n",
    "            code_snippet = observation\n",
    "        elif tool_name == \"code_executor\":\n",
    "            execution_output = observation\n",
    "\n",
    "    if execution_output is None:\n",
    "        return None\n",
    "\n",
    "    return execution_store.save(session_id, code_snippet, execution_output, question)\n",
    "\n",
    "agent_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that answers ONLY in Korean. \"\n",
    "            \"You must follow these rules:\\n\"\n",
    "            \"1. If q_type is 'domain_specific', you MUST use tools to generate code and execute it.\"\n",
    "            \"2. Use the result of code_executor, which is called 'return_var', to answer.\"\n",
    "            \"3. ONLY if 'return_var' is empty ([], None, or pd.DataFrame with no rows), respond with 'ì°¸ì¡°í•  ì •ë³´ê°€ ì—†ì–´ì„œ ë‹µë³€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'\"\n",
    "            \"4. Otherwise, ALWAYS use 'return_var' as the basis of your answer, and you MUST ADD '[DATA]' prefix at the beginning of the answer.\"\n",
    "            \"5. After collect the data results, describe the data specifically and explain about the results for the user.\"\n",
    "            \"Always answer in Korean, never in English.\"\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"human\", \"{retrieved_data}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def agent(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Agent ì‹¤í–‰ í•¨ìˆ˜\n",
    "    - domain_specific ì§ˆë¬¸ì€ tools(code_generator + safe_code_executor) ì‚¬ìš©\n",
    "    - code ì‹¤í–‰ ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ êµ¬ì¡° ì ìš©\n",
    "    \"\"\"\n",
    "    session_id = state[\"session_id\"]\n",
    "    # íˆìŠ¤í† ë¦¬ì— dict ê·¸ëŒ€ë¡œ ë„£ì§€ ë§ê³  ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    "    chat_history = get_session_history(session_id)\n",
    "    chat_history.add_user_message(f\"question: {state['question']}, q_type: {state['q_type']}\")\n",
    "\n",
    "    try:\n",
    "        # Agent ìƒì„±\n",
    "        agent_obj = create_tool_calling_agent(model, tools, agent_prompt)\n",
    "\n",
    "        agent_executor = AgentExecutor(\n",
    "            agent=agent_obj,\n",
    "            tools=tools,\n",
    "            verbose=False,\n",
    "            max_iterations=10,\n",
    "            max_execution_time=120,\n",
    "            handle_parsing_errors=True,\n",
    "            return_intermediate_steps=True\n",
    "        )\n",
    "\n",
    "        agent_with_history = RunnableWithMessageHistory(\n",
    "            agent_executor,\n",
    "            get_session_history,\n",
    "            history_messages_key=\"chat_history\",\n",
    "        )\n",
    "\n",
    "        max_attempts = 3\n",
    "        for attempt in range(max_attempts):\n",
    "            try:\n",
    "                # Agent ì‹¤í–‰\n",
    "                result = agent_with_history.invoke(\n",
    "                    {\n",
    "                        \"input\": state[\"question\"],\n",
    "                        \"retrieved_data\": state.get(\"context\"),\n",
    "                        \"relevance\": state.get(\"relevance\"),\n",
    "                        \"session_id\": session_id  # <-- session_id ëª…ì‹œì  ì „ë‹¬\n",
    "                    },\n",
    "                    {'configurable': {'session_id': session_id}}\n",
    "                )\n",
    "\n",
    "                # ê²°ê³¼ì—ì„œ ì½”ë“œ ì‹¤í–‰ì´ í•„ìš”í•˜ë©´ tools ë‚´ë¶€ì—ì„œ ìë™ í˜¸ì¶œë¨\n",
    "                state['answer'] = result['output']\n",
    "                state['execution_id'] = capture_execution_snapshot(session_id, result.get('intermediate_steps'), state['question'])\n",
    "                return state\n",
    "\n",
    "            except Exception as e_inner:\n",
    "                print(f\"âš ï¸ ì—ì´ì „íŠ¸ ì‹œë„ {attempt+1}/{max_attempts} ì‹¤íŒ¨: {e_inner}\")\n",
    "                if attempt == max_attempts - 1:\n",
    "                    raise\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì—ì´ì „íŠ¸ ì‹¤í–‰ ìµœì¢… ì‹¤íŒ¨: {e}\")\n",
    "        state['answer'] = f\"ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ì°½ì—ì„œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.\"\n",
    "        return state\n",
    "\n",
    "########################################################################\n",
    "############################ Workflow Graph ############################\n",
    "########################################################################\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "workflow.add_node(\"Router\", router)\n",
    "workflow.add_node(\"Agent\", agent)\n",
    "\n",
    "workflow.add_edge(\"Router\", \"Agent\")\n",
    "workflow.add_edge(\"Agent\", END)\n",
    "\n",
    "workflow.set_entry_point(\"Router\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44551432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "í…ŒìŠ¤íŠ¸ 1: êµ¬ë³„ ê³µì¥ ìˆ˜ (Bar Chart ì˜ˆìƒ)\n",
      "================================================================================\n",
      "ì§ˆë¬¸: êµ¬ë³„ë¡œ ê³µì¥ ìˆ˜ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”\n",
      "ë°ì´í„°:\n",
      "  ì •ì œ_ì‹œêµ°êµ¬ëª…  ê³µì¥ìˆ˜\n",
      "0     ê°•ë‚¨êµ¬  150\n",
      "1     ì„œì´ˆêµ¬  120\n",
      "2     ì†¡íŒŒêµ¬  180\n",
      "3     ê°•ë™êµ¬   90\n",
      "4     ìš©ì‚°êµ¬  110\n",
      "ì¶”ì²œ ì‹œê°í™”: {'chart_type': 'bar_chart', 'x_axis': 'ì •ì œ_ì‹œêµ°êµ¬ëª…', 'y_axis': 'ê³µì¥ìˆ˜', 'orientation': 'vertical', 'has_location': True, 'group_by': 'ì •ì œ_ì‹œêµ°êµ¬ëª…', 'time_series': False}\n",
      "\n",
      "================================================================================\n",
      "í…ŒìŠ¤íŠ¸ 2: ì—…ì¢…ë³„ ë¹„ìœ¨ (Pie Chart ì˜ˆìƒ)\n",
      "================================================================================\n",
      "ì§ˆë¬¸: ì—…ì¢…ë³„ ë¹„ìœ¨ì„ ë³´ì—¬ì£¼ì„¸ìš”\n",
      "ë°ì´í„°:\n",
      "  ì •ì œ_ì—…ì¢…ëª…    ë¹„ìœ¨\n",
      "0    ì œì¡°ì—…  35.5\n",
      "1   ì„œë¹„ìŠ¤ì—…  28.3\n",
      "2    ê±´ì„¤ì—…  20.2\n",
      "3    ìœ í†µì—…  16.0\n",
      "ì¶”ì²œ ì‹œê°í™”: {'chart_type': 'pie_chart', 'x_axis': 'ì •ì œ_ì—…ì¢…ëª…', 'y_axis': 'ë¹„ìœ¨', 'orientation': '', 'has_location': False, 'group_by': 'ì •ì œ_ì—…ì¢…ëª…', 'time_series': False}\n",
      "\n",
      "================================================================================\n",
      "í…ŒìŠ¤íŠ¸ 3: ì—°ë„ë³„ ì¶”ì´ (Line Chart ì˜ˆìƒ)\n",
      "================================================================================\n",
      "ì§ˆë¬¸: ì—°ë„ë³„ ë“±ë¡ê±´ìˆ˜ ì¶”ì´ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”\n",
      "ë°ì´í„°:\n",
      "     ì—°ë„  ë“±ë¡ê±´ìˆ˜\n",
      "0  2020  1200\n",
      "1  2021  1350\n",
      "2  2022  1280\n",
      "3  2023  1450\n",
      "4  2024  1500\n",
      "ì¶”ì²œ ì‹œê°í™”: {'chart_type': 'line_chart', 'x_axis': 'ì—°ë„', 'y_axis': 'ë“±ë¡ê±´ìˆ˜', 'orientation': '', 'has_location': False, 'group_by': '', 'time_series': True}\n",
      "\n",
      "================================================================================\n",
      "í…ŒìŠ¤íŠ¸ 4: Series ë°ì´í„°\n",
      "================================================================================\n",
      "ì§ˆë¬¸: ê° êµ¬ë³„ ê³µì¥ ê°œìˆ˜\n",
      "ë°ì´í„°:\n",
      "ê°•ë‚¨êµ¬    150\n",
      "ì„œì´ˆêµ¬    120\n",
      "ì†¡íŒŒêµ¬    180\n",
      "ê°•ë™êµ¬     90\n",
      "ìš©ì‚°êµ¬    110\n",
      "Name: ê³µì¥ìˆ˜, dtype: int64\n",
      "ì¶”ì²œ ì‹œê°í™”: {'chart_type': 'bar_chart', 'x_axis': 'index', 'y_axis': 'ê³µì¥ìˆ˜', 'orientation': 'vertical', 'has_location': True, 'group_by': 'index', 'time_series': False}\n"
     ]
    }
   ],
   "source": [
    "# 3. í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë°ì´í„° ìƒì„±\n",
    "# ì˜ˆì‹œ 1: êµ¬ë³„ ê³µì¥ ìˆ˜ ë°ì´í„°\n",
    "test_data_1 = pd.DataFrame({\n",
    "    'ì •ì œ_ì‹œêµ°êµ¬ëª…': ['ê°•ë‚¨êµ¬', 'ì„œì´ˆêµ¬', 'ì†¡íŒŒêµ¬', 'ê°•ë™êµ¬', 'ìš©ì‚°êµ¬'],\n",
    "    'ê³µì¥ìˆ˜': [150, 120, 180, 90, 110]\n",
    "})\n",
    "\n",
    "# ì˜ˆì‹œ 2: ì—…ì¢…ë³„ ë¹„ìœ¨ ë°ì´í„°\n",
    "test_data_2 = pd.DataFrame({\n",
    "    'ì •ì œ_ì—…ì¢…ëª…': ['ì œì¡°ì—…', 'ì„œë¹„ìŠ¤ì—…', 'ê±´ì„¤ì—…', 'ìœ í†µì—…'],\n",
    "    'ë¹„ìœ¨': [35.5, 28.3, 20.2, 16.0]\n",
    "})\n",
    "\n",
    "# ì˜ˆì‹œ 3: ì‹œê³„ì—´ ë°ì´í„°\n",
    "test_data_3 = pd.DataFrame({\n",
    "    'ì—°ë„': [2020, 2021, 2022, 2023, 2024],\n",
    "    'ë“±ë¡ê±´ìˆ˜': [1200, 1350, 1280, 1450, 1500]\n",
    "})\n",
    "\n",
    "# 4. í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "print(\"=\" * 80)\n",
    "print(\"í…ŒìŠ¤íŠ¸ 1: êµ¬ë³„ ê³µì¥ ìˆ˜ (Bar Chart ì˜ˆìƒ)\")\n",
    "print(\"=\" * 80)\n",
    "question_1 = \"êµ¬ë³„ë¡œ ê³µì¥ ìˆ˜ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”\"\n",
    "result_1 = infer_visualization_type(question_1, test_data_1)\n",
    "print(f\"ì§ˆë¬¸: {question_1}\")\n",
    "print(f\"ë°ì´í„°:\\n{test_data_1}\")\n",
    "print(f\"ì¶”ì²œ ì‹œê°í™”: {result_1}\")\n",
    "print()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"í…ŒìŠ¤íŠ¸ 2: ì—…ì¢…ë³„ ë¹„ìœ¨ (Pie Chart ì˜ˆìƒ)\")\n",
    "print(\"=\" * 80)\n",
    "question_2 = \"ì—…ì¢…ë³„ ë¹„ìœ¨ì„ ë³´ì—¬ì£¼ì„¸ìš”\"\n",
    "result_2 = infer_visualization_type(question_2, test_data_2)\n",
    "print(f\"ì§ˆë¬¸: {question_2}\")\n",
    "print(f\"ë°ì´í„°:\\n{test_data_2}\")\n",
    "print(f\"ì¶”ì²œ ì‹œê°í™”: {result_2}\")\n",
    "print()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"í…ŒìŠ¤íŠ¸ 3: ì—°ë„ë³„ ì¶”ì´ (Line Chart ì˜ˆìƒ)\")\n",
    "print(\"=\" * 80)\n",
    "question_3 = \"ì—°ë„ë³„ ë“±ë¡ê±´ìˆ˜ ì¶”ì´ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”\"\n",
    "result_3 = infer_visualization_type(question_3, test_data_3)\n",
    "print(f\"ì§ˆë¬¸: {question_3}\")\n",
    "print(f\"ë°ì´í„°:\\n{test_data_3}\")\n",
    "print(f\"ì¶”ì²œ ì‹œê°í™”: {result_3}\")\n",
    "print()\n",
    "\n",
    "# 5. Series ë°ì´í„° í…ŒìŠ¤íŠ¸\n",
    "print(\"=\" * 80)\n",
    "print(\"í…ŒìŠ¤íŠ¸ 4: Series ë°ì´í„°\")\n",
    "print(\"=\" * 80)\n",
    "test_series = pd.Series([150, 120, 180, 90, 110], \n",
    "                        index=['ê°•ë‚¨êµ¬', 'ì„œì´ˆêµ¬', 'ì†¡íŒŒêµ¬', 'ê°•ë™êµ¬', 'ìš©ì‚°êµ¬'])\n",
    "test_series.name = 'ê³µì¥ìˆ˜'\n",
    "question_4 = \"ê° êµ¬ë³„ ê³µì¥ ê°œìˆ˜\"\n",
    "result_4 = infer_visualization_type(question_4, test_series)\n",
    "print(f\"ì§ˆë¬¸: {question_4}\")\n",
    "print(f\"ë°ì´í„°:\\n{test_series}\")\n",
    "print(f\"ì¶”ì²œ ì‹œê°í™”: {result_4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c9a6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5908716f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e06aea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
